[{"title":"AnyIO-源码解读","path":"/2025/09/01/AnyIO-源码解读/","content":"AnyIO 是一个“后端无关”的异步并发与网络库：对上提供统一的高层 API（任务组、取消域、流、同步原语、线程&#x2F;进程桥、子进程、文件 I&#x2F;O、信号处理、pytest 集成），对下可在 asyncio 或 Trio 上运行。它将 Trio 的结构化并发（Structured Concurrency, SC） 模型（任务组、取消传播、失败即取消）推广到 asyncio，从而让应用与库在两大生态间能“一次编写，两处运行”。 核心卖点： 统一 API，隐藏后端差异 Trio 风格的结构化并发（TaskGroup、CancelScope） 可靠的网络&#x2F;流抽象（TCP&#x2F;UDP&#x2F;UNIX、TLS、内存流）、Happy Eyeballs 连接策略 简明的线程&#x2F;进程桥（to_thread&#x2F;from_thread + CapacityLimiter） 一流的测试体验（pytest 插件：同一套测试对两个后端跑） 目录结构1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950│ from_thread.py│ lowlevel.py│ py.typed│ pytest_plugin.py│ to_interpreter.py│ to_process.py│ to_thread.py│ __init__.py│├─abc│ _eventloop.py│ _resources.py│ _sockets.py│ _streams.py│ _subprocesses.py│ _tasks.py│ _testing.py│ __init__.py│├─streams│ buffered.py│ file.py│ memory.py│ stapled.py│ text.py│ tls.py│ __init__.py│├─_backends│ _asyncio.py│ _trio.py│ __init__.py│└─_core _asyncio_selector_thread.py _contextmanagers.py _eventloop.py _exceptions.py _fileio.py _resources.py _signals.py _sockets.py _streams.py _subprocesses.py _synchronization.py _tasks.py _tempfile.py _testing.py _typedattr.py __init__.py 后端适配（_backends） _asyncio.py 吐槽一下：源代码吧所有类、变量、方法都放在了这个文件里，导致代码定位很困难，徒增理解难度 _asyncio.py 的作用是把 AnyIO 的通用后端抽象（TaskGroup、CancelScope、streams、thread&#x2F;portal、子进程等）绑定到 asyncio：也就是把 AnyIO 的语义（Trio 风格的结构化并发、取消域、异常聚合、流抽象、线程桥等）在 asyncio 上“实现出来并修补 asyncio 与 AnyIO 语义差异” 1234567891011121314151617181920if sys.version_info &gt;= (3, 11): from asyncio import Runner from typing import TypeVarTuple, Unpackelse: import contextvars import enum import signal from asyncio import coroutines, events, exceptions, tasks from exceptiongroup import BaseExceptionGroup from typing_extensions import TypeVarTuple, Unpack class _State(enum.Enum): CREATED = &quot;created&quot; INITIALIZED = &quot;initialized&quot; CLOSED = &quot;closed&quot; class Runner: # Copied from CPython 3.11 ... Runner 实现首先是直接复制了 CPython3.11 对于 Runner 的实现，对齐低版本 python ayncio 的差异性。这里应该是借鉴了 Trio 的一些设计思想，AnyIO 的出发点也是整合Trio 和 AsyncIO 的生态 为什么要有 Runner？ 是为了在“一个进程里多次运行不同顶层协程”时，依旧能保持事件循环复用、contextvars 一致、资源正确回收——这是之前的 asyncio.run() 做不到的。 之前执行行为 12asyncio.run(foo()) # 运行完就彻底关闭asyncio.run(bar()) # 两个完全不同的循环，contextvars 也断了 旧版本解决方案, 主动创建事件循环，并一直复用 loop 每次 run_until_complete 会清空任务队列，但循环本身还活着。 如果忘了 close()，线程结束时会触发 “Event loop is closed” RuntimeError。 123456789101112131415import asyncio# 第一次初始化loop = asyncio.new_event_loop()# 设为全局默认asyncio.set_event_loop(loop) try: loop.run_until_complete(coro1()) loop.run_until_complete(coro2()) ...finally: loop.run_until_complete(loop.shutdown_asyncgens()) loop.run_until_complete(loop.shutdown_default_executor()) loop.close() 而 Runner 实现 了以下功能 上下文管理器：一次创建，可反复 runner.run(coro)，事件循环和 contextvars.Context 得以复用。 统一清理：离开 with 语句时自动关闭循环、终结异步生成器、停止默认线程池。 可控 Ctrl-C：内置信号处理器，第一次 Ctrl-C 发 CancelledError，第二次立即抛 KeyboardInterrupt，避免僵尸循环。 可选 debug &#x2F; 自定义 loop_factory：调试、性能调优更方便 123456789import asyncioasync def hello(name): await asyncio.sleep(0.1) return f&quot;Hello &#123;name&#125;&quot;with asyncio.Runner() as runner: print(runner.run(hello(&quot;Alice&quot;))) print(runner.run(hello(&quot;Bob&quot;))) 两段协程共用同一个事件循环，且退出 with 后自动清理。 任务组任务组实现了结构化并发（它确保并发操作具有明确定义的嵌套生命周期，是一种编程范式），任务组充当并发任务的监督者 AnyIO 中结构化并发的关键原则： 子任务不能超过其父任务的作用域 子任务中的错误会传播到父任务 取消从父级传播到子级 所有衍生任务必须在父级退出之前完成 关键代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215class TaskGroup(abc.TaskGroup): &quot;&quot;&quot; 一个“可等待”的上下文管理器： with 语句块里可以 start() / start_soon() 扔子任务， 离开 with 时会自动： - 等待所有子任务结束 - 若任何子任务抛异常，则取消其余任务 - 把异常重新抛出给调用者 &quot;&quot;&quot; # ---------- 初始化 ---------- def __init__(self) -&gt; None: self._active = False # 标记当前是否已进入 with 块 self._exiting = False # 正在退出 with（防止重复取消） self._exceptions: list[BaseException] = [] # 收集子任务异常 self._tasks: set[asyncio.Task] = set() # 当前活跃的子任务 self._cancel_scope: CancelScope | None = None # 用来级联取消 # ↑ 利用 asyncio.Future 做“事件通知”： # 当最后一个子任务完成时 set_result(None)，主循环就醒来继续 # ---------- 进入 with 语句 ---------- async def __aenter__(self) -&gt; TaskGroup: self._cancel_scope = CancelScope() # 创建根取消作用域 self._active = True return self # ---------- 退出 with 语句 ---------- async def __aexit__(self, exc_type, exc_val, exc_tb): try: # 1️⃣ 如果 with 块本身抛了异常，先把任务组取消 if exc_val is not None: self.cancel_scope.cancel() # 如果是“非取消”异常，记录下来 if not isinstance(exc_val, CancelledError): self._exceptions.append(exc_val) loop = get_running_loop() try: if self._tasks: # 还有子任务没跑完 with CancelScope() as wait_scope: # 新建一个“等待作用域” while self._tasks: # 轮询直到全部结束 self._on_completed_fut = loop.create_future() try: await self._on_completed_fut # 挂起，直到最后一个任务 done except CancelledError as exc: # 🔥 关键点：屏蔽后续取消，防止循环取消风暴 wait_scope.shield = True self.cancel_scope.cancel() # 如果之前没有异常，把这次取消记录为“主因” if exc_val is None or ( isinstance(exc_val, CancelledError) and not is_anyio_cancellation(exc) ): exc_val = exc self._on_completed_fut = None else: # 没有子任务也要至少做一次 checkpoint await AsyncIOBackend.cancel_shielded_checkpoint() self._active = False # 2️⃣ 把所有子异常打包成 BaseExceptionGroup if self._exceptions: raise BaseExceptionGroup( &quot;unhandled errors in a TaskGroup&quot;, self._exceptions ) from None elif exc_val: raise exc_val except BaseException as exc: # 如果 cancel_scope 决定吞掉异常，返回 True（不继续抛） if self.cancel_scope.__exit__(type(exc), exc, exc.__traceback__): return True raise finally: # 避免循环引用 del exc_val, exc_tb, self._exceptions def start_soon( self, func: Callable[..., Awaitable[Any]], *args: object, name: object = None, ) -&gt; None: task = self._spawn(func, args, name, None) async def start( self, func: Callable[..., Awaitable[Any]], *args: object, name: object = None, ) -&gt; Any: &quot;&quot;&quot; 立即启动子任务，等待它产出第一个值后返回； 若子任务启动瞬间爆炸，则保护调用者不被任务组级联取消淹没。 &quot;&quot;&quot; if not self._active: raise RuntimeError(&quot;必须在 TaskGroup 活跃期 start&quot;) future: asyncio.Future = asyncio.Future() # 用来传回“首值” task = self._spawn(func, args, name, future) # 绑定 future # 🔥 关键：屏蔽取消作用域 # 如果 task 在 yield 第一个值前就抛异常，任务组会立即取消， # 导致本方法也被 CancelledError 打断，无法把原始异常交给调用者。 try: return await future except asyncio.CancelledError: # 1. 先给肇事任务发取消 task.cancel() # 2. 用 shield=True 的 CancelScope 保护当前栈帧 # 避免任务组的级联取消把父任务也杀掉 with CancelScope(shield=True), suppress(asyncio.CancelledError): await task # 等它真正结束，吞掉内部 CancelledError raise # 把真正的异常重新抛给调用者 # ---------- 内部：真正创建 task ---------- def _spawn( self, func: Callable[..., Awaitable[Any]], args: tuple, name: object, task_status_future: asyncio.Future | None = None, ) -&gt; asyncio.Task: &quot;&quot;&quot; task_status_future 用于 `start()` 协议： - 子任务调用 task_status.started(value) 会 set_result(value) - 子任务崩溃时会 set_exception(...) &quot;&quot;&quot; def task_done(_task: asyncio.Task) -&gt; None: # 1️⃣ 清理 bookkeeping task_state = _task_states[_task] # 通过弱引用映射拿到 TaskState task_state.cancel_scope._tasks.remove(_task) self._tasks.remove(_task) del _task_states[_task] # 2️⃣ 如果这是最后一个任务，叫醒 __aexit__ 里的 while if self._on_completed_fut is not None and not self._tasks: try: self._on_completed_fut.set_result(None) except asyncio.InvalidStateError: pass # 3️⃣ 收集异常 try: exc = _task.exception() except CancelledError as e: # 把链式 CancelledError 压平 while isinstance(e.__context__, CancelledError): e = e.__context__ exc = e if exc is not None: # 如果 task_status_future 已经被取消（host task 崩溃），直接跳过 if task_status_future is not None and task_status_future.cancelled(): return # 正常记录异常 or 转交给 task_status_future if task_status_future is None or task_status_future.done(): if not isinstance(exc, CancelledError): self._exceptions.append(exc) if not self.cancel_scope._effectively_cancelled: self.cancel_scope.cancel() else: task_status_future.set_exception(exc) elif task_status_future is not None and not task_status_future.done(): # 子任务没调用 task_status.started() task_status_future.set_exception( RuntimeError(&quot;Child exited without calling task_status.started()&quot;) ) # 4️⃣ 创建 asyncio.Task if not self._active: raise RuntimeError(&quot;TaskGroup 未激活&quot;) kwargs = &#123;&#125; if task_status_future: parent_id = id(current_task()) kwargs[&quot;task_status&quot;] = _AsyncioTaskStatus( task_status_future, id(self.cancel_scope._host_task) ) else: parent_id = id(self.cancel_scope._host_task) coro = func(*args, **kwargs) if not iscoroutine(coro): raise TypeError(&quot;期望协程对象&quot;) name = get_callable_name(func) if name is None else str(name) loop = asyncio.get_running_loop() # 支持自定义 task factory（如 eager task） if ( (factory := loop.get_task_factory()) and getattr(factory, &quot;__code__&quot;, None) is _eager_task_factory_code and (closure := getattr(factory, &quot;__closure__&quot;, None)) ): custom_task_constructor = closure[0].cell_contents task = custom_task_constructor(coro, loop=loop, name=name) else: task = create_task(coro, name=name) # 把 task 挂到 cancel_scope 的私有集合里，实现级联取消 _task_states[task] = TaskState( parent_id=parent_id, cancel_scope=self.cancel_scope ) self.cancel_scope._tasks.add(task) # 让 cancel_scope.cancel() 能遍历 self._tasks.add(task) task.add_done_callback(task_done) return task 两个方法 start_soon 不等待任务执行立即返回，所以无法从生成的任务中获取返回值，也不知道任务何时真正开始运行。start立即执行，可以从生成的任务返回一个值 任务状态表与异常聚合AnyIO 要在 asyncio 上提供 Trio 风格“结构化并发”的语义：任何子任务异常都会触发取消组内其它任务并在退出时聚合异常（ExceptionGroup）。asyncio 原生行为在早期版本上与 Trio 不同，需在门面层统一语义。 取消作用域是一种上下文管理器，它定义了一段可作为一个单元取消的代码区域。取消作用域可以嵌套，取消外层作用域会自动取消所有内层作用域。 关键代码 12345678910111213141516171819202122232425262728293031323334353637class CancelScope(BaseCancelScope): def __init__(self, deadline: float = math.inf, shield: bool = False): self._deadline = deadline self._shield = shield # 比较典型的树形结构 self._parent_scope: CancelScope | None = None self._child_scopes: set[CancelScope] = set() ... # 围绕树形结构的操作 def __enter__(self) -&gt; CancelScope: # 把当前任务从原父节点摘下，挂到新的 CancelScope 节点下 → 树向下长出一层。 ... def __exit__( self, exc_type: type[BaseException] | None, exc_val: BaseException | None, exc_tb: TracebackType | None, ) -&gt; bool: # 把当前任务从当前节点摘下，重新挂回原父节点 → 树向上合并一层。 ... class TaskState: &quot;&quot;&quot; Encapsulates auxiliary task information that cannot be added to the Task instance itself because there are no guarantees about its implementation. &quot;&quot;&quot; __slots__ = &quot;parent_id&quot;, &quot;cancel_scope&quot;, &quot;__weakref__&quot; def __init__(self, parent_id: int | None, cancel_scope: CancelScope | None): self.parent_id = parent_id self.cancel_scope = cancel_scope_task_states: WeakKeyDictionary[asyncio.Task, TaskState] = WeakKeyDictionary() 总结： 文件维护 _task_states（任务 → TaskState），每个 TaskState 保留该任务的 cancel_scope 等信息；TaskGroup._spawn() 在创建 task 时把它插入 _task_states，并让子任务继承父 cancel scope。 子任务完成回调 task_done：如果子任务抛出异常（非 CancelledError），会把异常加入该 TaskGroup 的 _exceptions 列表，并触发 self.cancel_scope.cancel() 来取消其它子任务；最终在 TaskGroup 退出时把多个异常聚合为 BaseExceptionGroup 或重新抛单个异常。这样实现了“失败即取消 + 异常聚合”。 WorkerThread123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384WorkerThread(Thread): MAX_IDLE_TIME = 10 # seconds def __init__( self, root_task: asyncio.Task, workers: set[WorkerThread], idle_workers: deque[WorkerThread], ): super().__init__(name=&quot;AnyIO worker thread&quot;) self.root_task = root_task # 绑定的 asyncio 主循环（用它把结果送回）。 self.workers = workers self.idle_workers = idle_workers # 全局双端队列，线程空闲时把自己塞回去以便复用。 self.loop = root_task._loop self.queue: Queue[ tuple[Context, Callable, tuple, asyncio.Future, CancelScope] | None ] = Queue(2) self.idle_since = AsyncIOBackend.current_time() # 记录最近一次变成空闲的时间戳，用于过期淘汰。 self.stopping = False def _report_result( self, future: asyncio.Future, result: Any, exc: BaseException | None ) -&gt; None: # 更新空闲时间 self.idle_since = AsyncIOBackend.current_time() if not self.stopping: # 把自己放回复用队列 self.idle_workers.append(self) if not future.cancelled(): if exc is not None: if isinstance(exc, StopIteration): new_exc = RuntimeError(&quot;coroutine raised StopIteration&quot;) new_exc.__cause__ = exc exc = new_exc future.set_exception(exc) else: future.set_result(result) def run(self) -&gt; None: # 把当前事件循环和后端类注册到线程 with claim_worker_thread(AsyncIOBackend, self.loop): while True: # 阻塞等待任务或 None(关闭) item = self.queue.get() if item is None: # Shutdown command received return context, func, args, future, cancel_scope = item if not future.cancelled(): # 已经被上层取消 → 直接丢 result = None exception: BaseException | None = None threadlocals.current_cancel_scope = cancel_scope try: # 在“临时上下文”里跑一段代码，跑完自动恢复旧上下文。 result = context.run(func, *args) except BaseException as exc: exception = exc finally: del threadlocals.current_cancel_scope # 把结果/异常送回事件循环 if not self.loop.is_closed(): self.loop.call_soon_threadsafe( self._report_result, future, result, exception ) del result, exception self.queue.task_done() del item, context, func, args, future, cancel_scope def stop(self, f: asyncio.Task | None = None) -&gt; None: self.stopping = True self.queue.put_nowait(None) self.workers.discard(self) try: self.idle_workers.remove(self) except ValueError: pass AnyIO 提供了两个混合类来简化上下文管理器的实现： ContextManagerMixin- 用于实现同步上下文管理器 AsyncContextManagerMixin- 用于实现异步上下文管理器 这些混合器提供了一种基于生成器的方法来实现上下文管理器，类似于 Python 的内置@contextmanager和@asynccontextmanager装饰器 backend123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140class AsyncIOBackend(AsyncBackend): @classmethod def run( cls, func: Callable[..., Awaitable[T_Retval]], args: tuple, kwargs: dict[str, Any], options: dict[str, Any], ) -&gt; T_Retval: &quot;&quot;&quot; 等价于 asyncio.run()，但支持 uvloop、debug 等选项。 内部用标准库 3.11+ 的 asyncio.Runner。 &quot;&quot;&quot; @wraps(func) async def wrapper() -&gt; T_Retval: task = cast(asyncio.Task, current_task()) task.set_name(get_callable_name(func)) # 让栈追踪更好看 _task_states[task] = TaskState(None, None) # 初始化任务状态 try: return await func(*args, **kwargs) finally: del _task_states[task] # 清理弱引用，避免泄漏 debug = options.get(&quot;debug&quot;) loop_factory = options.get(&quot;loop_factory&quot;) if loop_factory is None and options.get(&quot;use_uvloop&quot;, False): import uvloop loop_factory = uvloop.new_event_loop # 使用 Runner 实现多 run 复用 with Runner(debug=debug, loop_factory=loop_factory) as runner: return runner.run(wrapper()) # ---------- 取消相关工具 ---------- @classmethod async def checkpoint(cls) -&gt; None: &quot;&quot;&quot;强制一次事件循环迭代，让出任务调度，相当于 trio.lowlevel.checkpoint() &quot;&quot;&quot; await sleep(0) @classmethod async def checkpoint_if_cancelled(cls) -&gt; None: &quot;&quot;&quot; 如果当前任务或其任一父 CancelScope 已被取消， 立即抛出 CancelledError；否则什么都不做。 &quot;&quot;&quot; task = current_task() if task is None: return try: cancel_scope = _task_states[task].cancel_scope except KeyError: return while cancel_scope: if cancel_scope.cancel_called: await sleep(0) # 触发真正的 asyncio.CancelledError elif cancel_scope.shield: # 被屏蔽，停止向上检查 break else: cancel_scope = cancel_scope._parent_scope @classmethod async def cancel_shielded_checkpoint(cls) -&gt; None: &quot;&quot;&quot;在屏蔽取消的状态下做一次 checkpoint（让出调度但不响应取消）&quot;&quot;&quot; with CancelScope(shield=True): await sleep(0) # ---------- 取消作用域 ---------- @classmethod def create_cancel_scope( cls, *, deadline: float = math.inf, shield: bool = False ) -&gt; CancelScope: return CancelScope(deadline=deadline, shield=shield) # ---------- 线程池 ---------- @classmethod async def run_sync_in_worker_thread( cls, func: Callable[..., T_Retval], args: tuple, *, abandon_on_cancel: bool = False, limiter: abc.CapacityLimiter | None = None, ) -&gt; T_Retval: &quot;&quot;&quot; 把同步函数丢到工作线程执行，返回 awaitable 的结果。 支持容量限制器、取消时是否放弃线程。 &quot;&quot;&quot; await cls.checkpoint() # 让调度器先跑一次，避免死锁 # 惰性初始化线程池相关全局变量 try: idle_workers = _threadpool_idle_workers.get() workers = _threadpool_workers.get() except LookupError: idle_workers = deque() workers = set() _threadpool_idle_workers.set(idle_workers) _threadpool_workers.set(workers) async with limiter or cls.current_default_thread_limiter(): # 若 abandon_on_cancel=False，则取消时**不**杀线程 with CancelScope(shield=not abandon_on_cancel) as scope: future = asyncio.Future[T_Retval]() root_task = find_root_task() # 复用或新建 WorkerThread if not idle_workers: worker = WorkerThread(root_task, workers, idle_workers) worker.start() workers.add(worker) root_task.add_done_callback(worker.stop) else: worker = idle_workers.pop() # 清理过期空闲线程…… ... # 拷贝上下文 context = copy_context() context.run(sniffio.current_async_library_cvar.set, None) worker.queue.put_nowait((context, func, args, future, scope)) return await future # ---------- 其他工厂方法 ---------- @classmethod def create_task_group(cls) -&gt; abc.TaskGroup: ... @classmethod def create_lock(cls, *, fast_acquire: bool) -&gt; abc.Lock: ... @classmethod def create_semaphore(cls, initial_value: int, *, max_value=None, fast_acquire=False) -&gt; abc.Semaphore: ... @classmethod def create_event(cls) -&gt; abc.Event: ... @classmethod def connect_tcp(cls, host: str, port: int, local_address=None) -&gt; abc.SocketStream: ... @classmethod def current_time(cls) -&gt; float: ... ... 上下文变量（contextvars）从异步任务传播到工作线程。这意味着在异步任务中设置的任何上下文变量都将在工作线程中可用，但是对工作线程中的上下文变量所做的任何更改都不会传播回异步任务： 12345678910111213import contextvarscv = contextvars.ContextVar(&#x27;demo&#x27;, default=&#x27;global&#x27;)def show(): print(cv.get())# 临时改写ctx = contextvars.copy_context()ctx.run(lambda: [cv.set(&#x27;local&#x27;), show()]) # 输出 local# 原上下文不受影响show() # 输出 global _tiro.py对于 tiro 的改造比较少，基本是使用 tiro 的原本功能 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100class CancelScope(BaseCancelScope): def __new__( cls, original: trio.CancelScope | None = None, **kwargs: object ) -&gt; CancelScope: return object.__new__(cls) def __init__(self, original: trio.CancelScope | None = None, **kwargs: Any) -&gt; None: self.__original = original or trio.CancelScope(**kwargs) def __enter__(self) -&gt; CancelScope: self.__original.__enter__() return self def __exit__( self, exc_type: type[BaseException] | None, exc_val: BaseException | None, exc_tb: TracebackType | None, ) -&gt; bool: return self.__original.__exit__(exc_type, exc_val, exc_tb) def cancel(self) -&gt; None: self.__original.cancel() @property def deadline(self) -&gt; float: return self.__original.deadline @deadline.setter def deadline(self, value: float) -&gt; None: self.__original.deadline = value @property def cancel_called(self) -&gt; bool: return self.__original.cancel_called @property def cancelled_caught(self) -&gt; bool: return self.__original.cancelled_caught @property def shield(self) -&gt; bool: return self.__original.shield @shield.setter def shield(self, value: bool) -&gt; None: self.__original.shield = valueclass TaskGroup(abc.TaskGroup): def __init__(self) -&gt; None: self._active = False self._nursery_manager = trio.open_nursery(strict_exception_groups=True) self.cancel_scope = None # type: ignore[assignment] async def __aenter__(self) -&gt; TaskGroup: self._active = True self._nursery = await self._nursery_manager.__aenter__() self.cancel_scope = CancelScope(self._nursery.cancel_scope) return self async def __aexit__( self, exc_type: type[BaseException] | None, exc_val: BaseException | None, exc_tb: TracebackType | None, ) -&gt; bool: try: # trio.Nursery.__exit__ returns bool; .open_nursery has wrong type return await self._nursery_manager.__aexit__(exc_type, exc_val, exc_tb) # type: ignore[return-value] except BaseExceptionGroup as exc: if not exc.split(trio.Cancelled)[1]: raise trio.Cancelled._create() from exc raise finally: del exc_val, exc_tb self._active = False def start_soon( self, func: Callable[[Unpack[PosArgsT]], Awaitable[Any]], *args: Unpack[PosArgsT], name: object = None, ) -&gt; None: if not self._active: raise RuntimeError( &quot;This task group is not active; no new tasks can be started.&quot; ) self._nursery.start_soon(func, *args, name=name) async def start( self, func: Callable[..., Awaitable[Any]], *args: object, name: object = None ) -&gt; Any: if not self._active: raise RuntimeError( &quot;This task group is not active; no new tasks can be started.&quot; ) return await self._nursery.start(func, *args, name=name) 核心组件（_core）由于基础组件很多这里只做部分代码解析 同步原语AnyIO 提供了几个与asyncio和trio后端兼容的同步原语： 事件：发生某事时在任务之间发出信号 锁：确保对共享资源的独占访问 条件：将锁与等待条件成立的能力结合起来 信号量：控制对有限数量资源的访问 CapacityLimiter：限制并发操作数 ResourceGuard：保护资源免于并发使用 对于 Tiro, 同步原语的实现基本还是用的源库的功能，这里主要对 asyncio 做分析 LockPS：task = cast(asyncio.Task, current_task()) 运行时完全等于直接赋值，但是这样写可以避免 mypy &#x2F; pyright &#x2F; pylance 报空指针错误 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374class Lock(BaseLock): def __new__(cls, *, fast_acquire: bool = False) -&gt; Lock: return object.__new__(cls) def __init__(self, *, fast_acquire: bool = False) -&gt; None: self._fast_acquire = fast_acquire self._owner_task: asyncio.Task | None = None # 获取锁的任务 self._waiters: deque[tuple[asyncio.Task, asyncio.Future]] = deque() # 等待队列 async def acquire(self) -&gt; None: task = cast(asyncio.Task, current_task()) if self._owner_task is None and not self._waiters: await AsyncIOBackend.checkpoint_if_cancelled() self._owner_task = task # 让「恰好没人竞争锁」时 省一次多余的 await asyncio.sleep(0)，直接拿到锁继续跑，提高极端高频低竞争场景下的吞吐量。 if not self._fast_acquire: try: await AsyncIOBackend.cancel_shielded_checkpoint() except CancelledError: self.release() raise return # 重入检查 if self._owner_task == task: raise RuntimeError(&quot;Attempted to acquire an already held Lock&quot;) # 进入排队 fut: asyncio.Future[None] = asyncio.Future() item = task, fut self._waiters.append(item) try: # 挂起直到被 release() 唤醒 await fut except CancelledError: self._waiters.remove(item) # 极端：刚巧轮到就被取消 if self._owner_task is task: self.release() raise self._waiters.remove(item) def acquire_nowait(self) -&gt; None: task = cast(asyncio.Task, current_task()) if self._owner_task is None and not self._waiters: self._owner_task = task return if self._owner_task is task: raise RuntimeError(&quot;Attempted to acquire an already held Lock&quot;) raise WouldBlock def locked(self) -&gt; bool: return self._owner_task is not None def release(self) -&gt; None: if self._owner_task != current_task(): raise RuntimeError(&quot;The current task is not holding this lock&quot;) for task, fut in self._waiters: if not fut.cancelled(): self._owner_task = task fut.set_result(None) return self._owner_task = None def statistics(self) -&gt; LockStatistics: task_info = AsyncIOTaskInfo(self._owner_task) if self._owner_task else None return LockStatistics(self.locked(), task_info, len(self._waiters)) 线程和进程管理 anyio.to_thread.run_sync 对于受 AnyIO 管理的线程 BlockingPortal- 对于不受 AnyIO 管理的外部线程 先看两个错误示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import asyncioimport threadingimport anyioasync def async_database_query(): print(&quot;执行异步数据库查询&quot;) await anyio.sleep(0.5) return [&quot;数据1&quot;, &quot;数据2&quot;]def thread_worker(): &quot;&quot;&quot;运行在线程中的函数&quot;&quot;&quot; print(&quot;在线程中工作&quot;) # -----------------错误示例------------------- # 从线程调用异步代码 try: result = anyio.from_thread.run(async_database_query) # 输出 ERROR: This function can only be run from an AnyIO worker thread print(f&quot;线程获得结果: &#123;result&#125;&quot;) except Exception as e: print(f&quot;错误: &#123;e&#125;&quot;) &quot;&quot;&quot; 需要将 thread = threading.Thread(target=thread_worker, name=&quot;工作线程&quot;) thread.start() 改为 result = await anyio.to_thread.run_sync(thread_worker) &quot;&quot;&quot; # -----------------错误示例------------------- new_loop = asyncio.new_event_loop() asyncio.set_event_loop(new_loop) # 尝试运行，能正常出结果 result = new_loop.run_until_complete(async_database_query()) print(f&quot;结果: &#123;result&#125;&quot;) new_loop.close() &quot;&quot;&quot; 1.多个事件循环冲突：主循环和线程中的循环会冲突 2.资源竞争：多个循环可能竞争相同的资源 3.不可预测的行为：可能导致随机崩溃或数据损坏 4.不是线程安全的：asyncio 的很多组件不是为多循环设计的 &quot;&quot;&quot;async def main_async(): &quot;&quot;&quot;主异步函数&quot;&quot;&quot; print(&quot;启动主异步任务&quot;) # 启动一个线程 thread = threading.Thread(target=thread_worker, name=&quot;工作线程&quot;) thread.start() # 同时执行其他异步工作 await anyio.sleep(1) print(&quot;主异步任务完成&quot;) thread.join()if __name__ == &quot;__main__&quot;: anyio.run(main_async) 正确示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import threadingimport anyiofrom anyio.from_thread import BlockingPortalasync def async_database_query(): print(&quot;执行异步数据库查询&quot;) await anyio.sleep(0.5) return [&quot;数据1&quot;, &quot;数据2&quot;]def thread_worker(portal: BlockingPortal): &quot;&quot;&quot;运行在外部线程中的函数&quot;&quot;&quot; print(&quot;在线程中工作&quot;) # 正确：使用BlockingPortal调用异步代码 try: result = portal.call(async_database_query) print(f&quot;线程获得结果: &#123;result&#125;&quot;) except Exception as e: print(f&quot;错误: &#123;e&#125;&quot;)async def main_async(): &quot;&quot;&quot;主异步函数&quot;&quot;&quot; print(&quot;启动主异步任务&quot;) # 创建BlockingPortal async with BlockingPortal() as portal: # 启动外部线程（由threading.Thread创建） thread = threading.Thread( target=thread_worker, args=(portal,), # 传入portal name=&quot;工作线程&quot; ) thread.start() # 同时执行其他异步工作 await anyio.sleep(1) print(&quot;主异步任务完成&quot;) thread.join()if __name__ == &quot;__main__&quot;: anyio.run(main_async) 可以简单理解为：如果项目中已经有同步的多线程代码，应该用 BlockingPortal，如果不是，则 anyio.to_thread.run_sync 更好，更方便 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129class BlockingPortal: &quot;&quot;&quot;允许外部线程在异步事件循环中执行代码的对象。&quot;&quot;&quot; def __new__(cls) -&gt; BlockingPortal: # 工厂方法：根据当前后端创建 BlockingPortal 实例 return get_async_backend().create_blocking_portal() def __init__(self) -&gt; None: # 保存事件循环所在的线程 ID self._event_loop_thread_id: int | None = get_ident() # 用于 stop() 通知的事件 self._stop_event = Event() # 内部的 TaskGroup，用于启动/管理异步任务 self._task_group = create_task_group() # 后端特定的 CancelledError 类 self._cancelled_exc_class = get_cancelled_exc_class() async def __aenter__(self) -&gt; BlockingPortal: # 进入 async with 时，启动 TaskGroup await self._task_group.__aenter__() return self async def __aexit__(...): # 退出 async with 时，调用 stop 并退出 TaskGroup await self.stop() return await self._task_group.__aexit__(...) def _check_running(self) -&gt; None: # 确认 portal 正常运行，且不是在事件循环线程内调用 if self._event_loop_thread_id is None: raise RuntimeError(&quot;This portal is not running&quot;) if self._event_loop_thread_id == get_ident(): raise RuntimeError(&quot;This method cannot be called from the event loop thread&quot;) async def sleep_until_stopped(self) -&gt; None: &quot;&quot;&quot;阻塞等待，直到 stop() 被调用。&quot;&quot;&quot; await self._stop_event.wait() async def stop(self, cancel_remaining: bool = False) -&gt; None: &quot;&quot;&quot; 停止 portal： - 不再接受新任务 - 解除 sleep_until_stopped - 可选：取消所有剩余任务 &quot;&quot;&quot; self._event_loop_thread_id = None self._stop_event.set() if cancel_remaining: self._task_group.cancel_scope.cancel() async def _call_func(...): &quot;&quot;&quot; 由 _spawn_task_from_thread 调用： - 执行目标函数 - 如果返回 awaitable，则在 CancelScope 中 await - 正确处理异常、取消，并写回 Future &quot;&quot;&quot; def callback(f: Future): ... try: retval_or_awaitable = func(*args, **kwargs) if isawaitable(retval_or_awaitable): with CancelScope() as scope: ... retval = await retval_or_awaitable else: retval = retval_or_awaitable except self._cancelled_exc_class: future.cancel() future.set_running_or_notify_cancel() except BaseException as exc: if not future.cancelled(): future.set_exception(exc) if not isinstance(exc, Exception): raise else: if not future.cancelled(): future.set_result(retval) finally: scope = None def _spawn_task_from_thread(...): &quot;&quot;&quot; 抽象方法：在事件循环线程中启动任务。 - 由具体后端实现 - 确保任务完成时，能正确解析 Future &quot;&quot;&quot; raise NotImplementedError def call(self, func, *args) -&gt; T_Retval: &quot;&quot;&quot; 在事件循环中同步执行函数。 - 如果返回 coroutine，会等待完成 - 对外表现为阻塞调用 &quot;&quot;&quot; return cast(T_Retval, self.start_task_soon(func, *args).result()) def start_task_soon(...): &quot;&quot;&quot; 异步地在 TaskGroup 中启动任务（从外部线程发起）。 - 返回 concurrent.futures.Future - 允许调用方取消 Future 来取消任务 &quot;&quot;&quot; self._check_running() f: Future = Future() self._spawn_task_from_thread(func, args, &#123;&#125;, name, f) return f def start_task(...): &quot;&quot;&quot; 类似 TaskGroup.start：在启动任务时，等待其调用 task_status.started()。 返回 (Future, task_status_value)。 &quot;&quot;&quot; def task_done(future: Future): ... self._check_running() task_status_future: Future = Future() task_status = _BlockingPortalTaskStatus(task_status_future) f: Future = Future() f.add_done_callback(task_done) self._spawn_task_from_thread(func, args, &#123;&quot;task_status&quot;: task_status&#125;, name, f) return f, task_status_future.result() def wrap_async_context_manager(self, cm): &quot;&quot;&quot; 将 async context manager 包装为 sync context manager： - 在内部启动任务，调用 __aenter__ / __aexit__ - 方便在同步代码中使用 async 上下文 &quot;&quot;&quot; return _BlockingAsyncContextManager(cm, self) 结语两年前阅读 uvicorn 的源码时也是用了AI，但是效果不尽人意。短短一年，AI 的进步已经能让整个项目全部投入其中，各个代码关键点全面解析，甚至还能做出图表让人更容易理解。 本文含有大量 AI 生成的内容 当前解析 anyio 版本 4.10.0 推荐阅读DeepWiki 原文","tags":["python","uvicron"]},{"title":"python json 库性能对比","path":"/2024/10/07/python-json-库性能对比/","content":"主要挑选了三个库进行对比: json, orjson, simdjson orjson 开源社区：https://github.com/ijl/orjson orjson 是一个快速、正确的 Python JSON 库。它 被评为最快的 JSON Python 库，并且比标准 json 库或其他第三方库更正确。它本机序列化 dataclass、 datetime、 numpy和 UUID实例。 与其他Python JSON库相比，它的特点和缺点： 序列化dataclass实例的速度是其他库的 40-50 倍 将datetime、date、 和time实例序列化为 RFC 3339 格式，例如“1970-01-01T00:00:00+00:00” 序列化numpy.ndarray实例的速度是其他库的 4-12 倍，内存使用量是其他库的 0.3 倍 漂亮的打印速度是标准库的 10 到 20 倍 序列化为bytes而不是str，即不是直接替换 序列化时str不将 unicode 转义为 ASCII，例如“好”而不是“\\u597d” 序列化float速度是其他库的 10 倍，反序列化速度是其他库的两倍 原生序列化str、int、list和 的子类dict，需要default指定如何序列化其他类 default使用钩子序列化任意类型 具有严格的UTF-8一致性，比标准库更正确 具有严格的 JSON 一致性，不支持 Nan&#x2F;Infinity&#x2F;-Infinity 具有对 53 位整数严格遵循 JSON 的选项，默认支持 64 位 不提供读取&#x2F;写入类文件对象的load()功能dump() simdjson 开源社区：https://github.com/simdjson/simdjson JSON 在互联网上随处可见。服务器花费“大量”时间来解析它。我们需要一种新的方法。simdjson 库使用常用的 SIMD 指令和微并行算法，解析 JSON 的速度比 RapidJSON 快 4 倍，比现代 C++ 的 JSON 快 25 倍。 快速：比常用的生产级 JSON 解析器快 4 倍以上。 破纪录的功能：以 6 GB&#x2F;s 的速度压缩 JSON，以 13 GB&#x2F;s 的速度验证 UTF-8，以 3.5 GB&#x2F;s 的速度验证 NDJSON。 简单：一流、易于使用且详细记录的 API。 严格：完整的 JSON 和 UTF-8 验证，无损解析。性能毫不妥协。 自动：在运行时选择适合 CPU 的解析器。无需配置。 可靠：从内存分配到错误处理，simdjson 的设计避免了意外。 测试代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879import jsonimport orjsonimport timeimport simdjsonimport matplotlib.pyplot as plttest_data = &#123; &quot;key1&quot;: &quot;value1&quot;,省略.. &quot;key100&quot;: &quot;value100&quot;&#125;test_data_str = json.dumps(test_data)def average_every_n(data, n): averaged_data = [] for i in range(0, len(data), n): chunk = data[i:i + n] averaged_data.append(sum(chunk) / len(chunk)) return averaged_datadef json_t(): times = [] for i in range(1, 10001): start_time = time.time() json.dumps(test_data) end_time = time.time() times.append(end_time - start_time) if i % 1000 == 0: averaged_data = average_every_n(times, 1000) yield i // 1000, averaged_data[-1]def orjson_t(): times = [] for i in range(1, 10001): start_time = time.time() orjson.dumps(test_data).decode(&#x27;utf-8&#x27;) end_time = time.time() times.append(end_time - start_time) if i % 1000 == 0: averaged_data = average_every_n(times, 1000) yield i // 1000, averaged_data[-1]def simdjson_t(): times = [] for i in range(1, 10001): start_time = time.time() simdjson.dumps(test_data) end_time = time.time() times.append(end_time - start_time) if i % 1000 == 0: averaged_data = average_every_n(times, 1000) yield i // 1000, averaged_data[-1]if __name__ == &#x27;__main__&#x27;: json_data = list(json_t()) orjson_data = list(orjson_t()) simdjson_data = list(simdjson_t()) # 绘制对比图 plt.plot(*zip(*json_data), label=&#x27;json&#x27;) plt.plot(*zip(*orjson_data), label=&#x27;orjson&#x27;) plt.plot(*zip(*simdjson_data), label=&#x27;simdjson&#x27;) plt.xlabel(&#x27;Iteration (x1000)&#x27;) plt.ylabel(&#x27;Average Time (seconds)&#x27;) plt.legend() plt.title(&#x27;JSON Serialization Performance Comparison&#x27;) plt.show() 测试结果注意：由于 orjson 是将对象序列化为bytes而不是str，即不是直接替换，所以加上 decode(&#39;utf-8&#39;) 将其转换成字符串 json dumps 的性能对比 json loads 的新能对比 可见 orjson 的性能是远超 python 的内置库和 simdjson 库的","tags":["python"]},{"title":"uvicorn-源码浅读","path":"/2024/10/07/uvicorn-源码浅读/","content":"前记Uvicorn是一个基于uvloop和httptools的ASGI服务器, 性能比较强劲， 通过它可以与使用ASGI规范的Python应用程序进行交互。ASGI与WSGI很像， 只不过ASGI原生支持HTTP2.0和WebSocket， 同时更多的是支持Python的Asyncio生态的WEB应用程序。通过了解Uvicron，能知道一个稳定的Web服务器的工作方式以及能更好的去了解其他基于ASGI的WEB应用程序 知识点 1uvloop 是一个用 Cython 编写的 asyncio 事件循环的快速替代品，它基于 libuv，这是一个高性能的跨平台异步 I&#x2F;O 库。uvloop 被设计为可以无缝替换 Python 标准库 asyncio 中的默认事件循环，从而提高异步编程的性能。它至少比 Node.js、gevent 以及其他 Python 异步框架要快两倍，其性能接近 Go 程序。 开源仓库：https://github.com/MagicStack/uvloop 使用方法 12345678pip install uvloopimport asyncioimport uvloopasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())# 编写asyncio的代码，与之前写的代码一致。# 内部的事件循环自动化会变为uvloopasyncio.run(...) 在 uvicorn 中的使用 1234567891011121314151617181920uvicorn/loops/auto.pydef auto_loop_setup(use_subprocess: bool = False) -&gt; None: try: import uvloop # noqa except ImportError: # pragma: no cover from uvicorn.loops.asyncio import asyncio_setup as loop_setup loop_setup(use_subprocess=use_subprocess) else: # pragma: no cover from uvicorn.loops.uvloop import uvloop_setup uvloop_setup(use_subprocess=use_subprocess)uvicorn/loops/uvloop.pyimport asyncioimport uvloopdef uvloop_setup(use_subprocess: bool = False) -&gt; None: asyncio.set_event_loop_policy(uvloop.EventLoopPolicy()) 缺点 目前不支持 windows 知识点 2ASGI（Asynchronous Server Gateway Interface）是一个用于网络应用的异步Python框架接口，用于处理HTTP和WebSocket请求。ASGI是同步WSGI（Web Server Gateway Interface）接口的异步继任者，它允许使用Python编写的异步框架来构建高性能的Web应用, 为什么使用 ASGI Most well established Python Web frameworks started out as WSGI-based frameworks. 大多数成熟的 Python Web 框架最初都是基于 WSGI 的框架。 WSGI applications are a single, synchronous callable that takes a request and returns a response. This doesn’t allow for long-lived connections, like you get with long-poll HTTP or WebSocket connections, which WSGI doesn’t support well. WSGI 应用程序是一个单一的同步可调用对象，它接受一个请求并返回一个响应。这不允许长时间保持连接，例如你在长轮询 HTTP 或 WebSocket 连接中所获得的那种，而 WSGI 对这些并不支持得很好。 Having an async concurrency model also allows for options such as lightweight background tasks, and can be less of a limiting factor for endpoints that have long periods being blocked on network I&#x2F;O such as dealing with slow HTTP requests. 采用异步并发模型还可以实现轻量级的后台任务，可以更少的被那些长时间被网络I&#x2F;O（如处理缓慢的HTTP请求）阻塞的端点所限制。 文档链接: https://www.uvicorn.org/#the-asgi-interface 最简单的 ASGI 应用 1234567891011121314async def app(scope, receive, send): assert scope[&#x27;type&#x27;] == &#x27;http&#x27; await send(&#123; &#x27;type&#x27;: &#x27;http.response.start&#x27;, &#x27;status&#x27;: 200, &#x27;headers&#x27;: [ [b&#x27;content-type&#x27;, b&#x27;text/plain&#x27;], ], &#125;) await send(&#123; &#x27;type&#x27;: &#x27;http.response.body&#x27;, &#x27;body&#x27;: b&#x27;Hello, world!&#x27;, &#125;) scope http 的内容： 1234567891011121314scope = &#123; &quot;type&quot;: &quot;http&quot;, &quot;http_version&quot;: &quot;1.1&quot;, &quot;method&quot;: &quot;GET&quot;, &quot;scheme&quot;: &quot;https&quot;, &quot;path&quot;: &quot;/&quot;, &quot;query_string&quot;: b&quot;search=red+blue&amp;maximum_price=20&quot;, &quot;headers&quot;: [ (b&quot;host&quot;, b&quot;www.example.org&quot;), (b&quot;accept&quot;, b&quot;application/json&quot;) ], &quot;client&quot;: (&quot;134.56.78.4&quot;, 1453), &quot;server&quot;: (&quot;www.example.org&quot;, 443)&#125; 与 wsgi 的 environ 字典非常相似 12345678910111213environ = &#123; &quot;REQUEST_METHOD&quot;: &quot;GET&quot;, &quot;SCRIPT_NAME&quot;: &quot;&quot;, &quot;PATH_INFO&quot;: &quot;/&quot;, &quot;QUERY_STRING&quot;: &quot;search=red+blue&amp;maximum_price=20&quot;, &quot;SERVER_NAME&quot;: &quot;www.example.org&quot;, &quot;SERVER_PORT&quot;: 443, &quot;REMOTE_HOST&quot;: &quot;134.56.78.4&quot;, &quot;REMOTE_PORT&quot;: 1453, &quot;SERVER_PROTOCOL&quot;: &quot;HTTP/1.1&quot;, &quot;HTTP_HOST&quot;: &quot;www.example.org&quot;, &quot;HTTP_ACCEPT&quot;: &quot;application/json&quot;,&#125; 实际上官访文档也解释了两者之间的兼容性：https://asgi.readthedocs.io/en/latest/specs/www.html#wsgi-compatibility 源码结构1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253├─lifespan│ │ off.py│ │ on.py│ │ __init__.py│├─loops│ │ asyncio.py│ │ auto.py│ │ uvloop.py│ │ __init__.py│├─middleware│ │ asgi2.py│ │ message_logger.py│ │ proxy_headers.py│ │ wsgi.py│ │ __init__.py│├─protocols│ │ utils.py│ │ __init__.py│ ││ ├─http│ │ │ auto.py│ │ │ flow_control.py│ │ │ h11_impl.py│ │ │ httptools_impl.py│ │ │ __init__.py│ ││ ├─websockets│ │ │ auto.py│ │ │ websockets_impl.py│ │ │ wsproto_impl.py│ │ │ __init__.py│├─supervisors│ │ basereload.py│ │ multiprocess.py│ │ statreload.py│ │ watchfilesreload.py│ │ watchgodreload.py│ │ __init__.py││ config.py│ importer.py│ logging.py│ main.py│ server.py│ workers.py│ _subprocess.py│ _types.py│ __init__.py│ __main__.py lifespan 告诉基于 ASGI 的应用程序uvicorn即将启动和停止的时间， uvicorn 在启动的时候会初始化，然后发送初始化协议并等待ASGI应用程序返回， 如果ASGI应用程序返回 complele 则 uvicorn 会继续运行， 返回 failed 则报错退出 我们先看 lifespan 这个目录有什么 123456789101112131415161718192021222324252627282930313233343536373839class LifespanOn: def __init__(self, config: Config) -&gt; None: self.logger = logging.getLogger(&quot;uvicorn.error&quot;) self.startup_event = asyncio.Event() self.shutdown_event = asyncio.Event() self.receive_queue: Queue[LifespanReceiveMessage] = asyncio.Queue() ... async def startup(self) -&gt; None: self.logger.info(&quot;Waiting for application startup.&quot;) # 获取事件循环 loop = asyncio.get_event_loop() # 这里只是创建了任务，让其在事件循环中等待执行，创建变量原因是添加 hard reference, 避免被 python 自动 gc main_lifespan_task = loop.create_task(self.main()) # noqa: F841 # Keep a hard reference to prevent garbage collection # See https://github.com/encode/uvicorn/pull/972 startup_event: LifespanStartupEvent = &#123;&quot;type&quot;: &quot;lifespan.startup&quot;&#125; # 发送启动事件到队列 await self.receive_queue.put(startup_event) await self.startup_event.wait() if self.startup_failed or (self.error_occured and self.config.lifespan == &quot;on&quot;): self.logger.error(&quot;Application startup failed. Exiting.&quot;) self.should_exit = True else: self.logger.info(&quot;Application startup complete.&quot;) async def main(self) -&gt; None: try: app = self.config.loaded_app scope: LifespanScope = &#123; &quot;type&quot;: &quot;lifespan&quot;, &quot;asgi&quot;: &#123;&quot;version&quot;: self.config.asgi_version, &quot;spec_version&quot;: &quot;2.0&quot;&#125;, &quot;state&quot;: self.state, &#125; await app(scope, self.receive, self.send) except BaseException as exc: ... asyncio.Event() 对象的使用 123456789101112131415161718192021222324252627282930313233import asyncioasync def waiter(event): print(&quot;Waiter is waiting for the event to be set.&quot;) await event.wait() print(&quot;Waiter has been awakened.&quot;)async def setter(event): print(&quot;Setter is going to set the event.&quot;) await asyncio.sleep(1) # 模拟一些异步操作 event.set() print(&quot;Event has been set.&quot;)async def main(): event = asyncio.Event() waiter_task = asyncio.create_task(waiter(event)) setter_task = asyncio.create_task(setter(event)) # 等待两个任务都完成 await waiter_task await setter_taskasyncio.run(main())# 输出Waiter is waiting for the event to be set.Setter is going to set the event.Event has been set.Waiter has been awakened. LifespanOff 比较简单 12345678910class LifespanOff: def __init__(self, config: Config) -&gt; None: self.should_exit = False self.state: dict[str, Any] = &#123;&#125; async def startup(self) -&gt; None: pass async def shutdown(self) -&gt; None: pass loops自动加载事件循环， 优先加载 uvloop 参考上文 知识点 1 middleware 里面是一些简单通用的中间件 PS: 这里的中间件和 fastapi 中的中间件是不同的，fastapi 的中间件是一个 ASGI 应用中上下文的切割，这里的中间件就是一个 ASGI 应用 wsgi.py 将 ASGI 服务转成 WSGI 服务 message_logger.py 传递消息的中间件 proxy_headers.py 一个应用程序通过代理（如Nginx、Apache等）与客户端连接时，客户端的请求会先经过代理服务器，然后再转发给应用程序。代理服务器在转发时，会添加一些特殊的HTTP头部，比如： X-Forwarded-For：记录原始客户端的IP地址。 X-Forwarded-Proto：记录客户端使用的协议（HTTP或HTTPS）。 然而，当应用程序收到请求时，默认情况下，它会认为请求是从代理服务器而不是从原始客户端发来的。所以，客户端的IP和协议信息可能会被代理的IP和协议覆盖。 这个中间件的作用就是让应用程序使用代理服务器传递过来的这些头部信息，从而获取到原始客户端的IP地址和协议，而不是代理服务器的IP和协议。这样，应用程序可以知道真正发起请求的客户端是谁，以及他们使用的是HTTP还是HTTPS。 protocols 里面存放着读取连接数据和解析消息体的协议， 如 HTTP 和 WebSockets, 可以把他认为是一个序列化器。 基础协议uvicorn 封装的对象继承于 asyncio.Protocol, 它是针对TCP协议的封装，包含以下六个方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243class BaseProtocol: def connection_made(self, transport): &quot;&quot;&quot; 在建立连接时调用. 参数是表示管道连接的transport, 此时得到的transport需要设置为该类的transport， 方便后续connection_lost控制关闭管道. &quot;&quot;&quot; def connection_lost(self, exc): &quot;&quot;&quot; 当连接丢失或关闭时调用, 根据exc判断是否要关闭trnasport. 参数是一个异常对象或None(后者表示接收到常规EOF或中止或关闭连接). &quot;&quot;&quot; def pause_writing(self): &quot;&quot;&quot; 当transport缓冲区超过高水位(high-water mark)时调用, 此时应该能控制外部不再写入数据（通常是一个asyncio.Future）, 同时应该通过transport.pause_reading来停止获取数据， 之后TCP就会通过拥塞机制使得客户端减缓发送数据的速度。 &quot;&quot;&quot; def resume_writing(self): &quot;&quot;&quot; 当transport缓冲区排放低于低水位线(low-water mark)时调用. 此时要释放标志， 使得外部可以继续写入数据， 同时通过transport.resume_reading来恢复获取数据， 之后TCP就会通过拥塞机制知道服务端的处理能力上来了， 使客户端加快发送速度。 &quot;&quot;&quot;class Protocol(BaseProtocol): def data_received(self, data): &quot;&quot;&quot; 通过该方法可以获取到客户端传输过来的数据 &quot;&quot;&quot; def eof_received(self): &quot;&quot;&quot; 当另一端调用write_eof()或等效函数时调用. 如果返回一个假值(包括None)，则传输将关闭自身。 如果它返回true值，则关闭传输取决于协议. &quot;&quot;&quot; 通过这些我们还不知道 uvicorn 做了哪些修改来达到跟应用程序进行通信，所以我们接着看一下 uvicorn 的具体实现 http里面有两种实现：httptools 和 h11_impl httptools 是一个用 C 语言编写的高性能 HTTP 库，它提供了一个快速的 HTTP 解析器和生成器。由于它是用 C 编写的，因此可以提供比纯 Python 库更高的性能。httptools 通常用于构建高性能的 Web 服务器和客户端，特别是在需要处理大量并发连接时。 h11 是一个纯 Python 编写的 HTTP&#x2F;1.1 协议的实现，它提供了一个简单、明确的 API 来处理 HTTP 消息。h11 的设计目标是易于理解和使用，而不是追求最高性能。 httptools 的内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102class ServerState: &quot;&quot;&quot; Shared servers state that is available between all protocol instances. &quot;&quot;&quot; def __init__(self) -&gt; None: self.total_requests = 0 self.connections: set[Protocols] = set() self.tasks: set[asyncio.Task[None]] = set() self.default_headers: list[tuple[bytes, bytes]] = []class HttpToolsProtocol(asyncio.Protocol): def __init__( self, config: Config, server_state: ServerState, app_state: dict[str, Any], _loop: asyncio.AbstractEventLoop | None = None, ) -&gt; None: if not config.loaded: config.load() self.config = config self.app = config.loaded_app self.loop = _loop or asyncio.get_event_loop() self.logger = logging.getLogger(&quot;uvicorn.error&quot;) self.access_logger = logging.getLogger(&quot;uvicorn.access&quot;) # 传入了 self self.parser = httptools.HttpRequestParser(self) # server_state 可以理解为一个容器 self.server_state = server_state self.connections = server_state.connections self.tasks = server_state.tasks # Per-connection state self.transport: asyncio.Transport = None # type: ignore[assignment] self.flow: FlowControl = None # type: ignore[assignment] # 请求处理流程的双端队列 self.pipeline: deque[tuple[RequestResponseCycle, ASGI3Application]] = deque() def connection_made( # type: ignore[override] self, transport: asyncio.Transport ) -&gt; None: # 添加实例本身到集合， 代表当前还有连接在处理 self.connections.add(self) self.transport = transport # 初始化流控制 self.flow = FlowControl(transport) # 简单的初始化实例trsnaport的相关编列 self.server = get_local_addr(transport) self.client = get_remote_addr(transport) self.scheme = &quot;https&quot; if is_ssl(transport) else &quot;http&quot; if self.logger.level &lt;= TRACE_LOG_LEVEL: prefix = &quot;%s:%d - &quot; % self.client if self.client else &quot;&quot; self.logger.log(TRACE_LOG_LEVEL, &quot;%sHTTP connection made&quot;, prefix) def connection_lost(self, exc: Exception | None) -&gt; None: # 从集合删除实例本身， 代表当前连接已经处理玩了， 不需要进入统计容器 self.connections.discard(self) if self.logger.level &lt;= TRACE_LOG_LEVEL: prefix = &quot;%s:%d - &quot; % self.client if self.client else &quot;&quot; self.logger.log(TRACE_LOG_LEVEL, &quot;%sHTTP connection lost&quot;, prefix) # 设置cycle， 告诉他连接已经断开 if self.cycle and not self.cycle.response_complete: self.cycle.disconnected = True if self.cycle is not None: self.cycle.message_event.set() if self.flow is not None: self.flow.resume_writing() if exc is None: self.transport.close() self._unset_keepalive_if_required() self.parser = None def _unset_keepalive_if_required(self): &quot;&quot;&quot;取消keep alive timeout的任务， 一般来说， 在发送数据后服务端会等待客户端发送数据， 如果超过多少秒没有发送数据则可以判断该客户端已经断开了， 服务端可以主动关闭连接 而uvicorn通过timeout_keep_alive_task来实现 &quot;&quot;&quot; if self.timeout_keep_alive_task is not None: self.timeout_keep_alive_task.cancel() self.timeout_keep_alive_task = None def data_received(self, data): self._unset_keepalive_if_required() try: # 接受字节数据， 并交由http解析器进行解析 self.parser.feed_data(data) except httptools.HttpParserError as exc: # 解析失败， 应该不是http协议的数据， 断开连接 msg = &quot;Invalid HTTP request received.&quot; self.logger.warning(msg, exc_info=exc) self.transport.close() except httptools.HttpParserUpgrade: # 已经超过了解析器能解析的协议版本， 应该交由更新的协议解析器处理 self.handle_upgrade() 该类中还有很多 on_xxx 的方法并没有被调用，是因为在初始化HTTP协议解析器的时候，uvicorn.protocol 把自己的实例传入了HTTP解析器中， 解析器会边接收数据边按照url, header, body来顺序解析， 并在执行每种数据解析后， 会通过回调告诉传入的实例， uvicorn 正是通过on_xxx 方法来监听这些回调并处理解析完的HTTP数据 可以看 httptools 的 parser 源码，是 CPython 写的: https://github.com/MagicStack/httptools/blob/master/httptools/parser/parser.pyx 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133class HttpToolsProtocol(asyncio.Protocol): def on_message_begin(self) -&gt; None: # 接收到请求的第一次解析，主要作用是初始化 scope self.url = b&quot;&quot; self.expect_100_continue = False self.headers = [] self.scope = &#123; # type: ignore[typeddict-item] &quot;type&quot;: &quot;http&quot;, &quot;asgi&quot;: &#123;&quot;version&quot;: self.config.asgi_version, &quot;spec_version&quot;: &quot;2.4&quot;&#125;, &quot;http_version&quot;: &quot;1.1&quot;, &quot;server&quot;: self.server, &quot;client&quot;: self.client, &quot;scheme&quot;: self.scheme, # type: ignore[typeddict-item] &quot;root_path&quot;: self.root_path, &quot;headers&quot;: self.headers, &quot;state&quot;: self.app_state.copy(), &#125; # Parser callbacks def on_url(self, url: bytes) -&gt; None: self.url += url def on_header(self, name: bytes, value: bytes) -&gt; None: &quot;&quot;&quot;解析器在解析header时， 是按照header一行一行进行解析的， 所以每一行header都会调用一次on_header, 并把他们存在实例的headers中&quot;&quot;&quot; name = name.lower() if name == b&quot;expect&quot; and value.lower() == b&quot;100-continue&quot;: self.expect_100_continue = True self.headers.append((name, value)) def on_headers_complete(self) -&gt; None: http_version = self.parser.get_http_version() method = self.parser.get_method() self.scope[&quot;method&quot;] = method.decode(&quot;ascii&quot;) if http_version != &quot;1.1&quot;: self.scope[&quot;http_version&quot;] = http_version if self.parser.should_upgrade() and self._should_upgrade(): # 如果发现当前http版本更加高级（比如websocket）, 则不再处理, 在另外一个逻辑会转到websocket处理 return parsed_url = httptools.parse_url(self.url) raw_path = parsed_url.path path = raw_path.decode(&quot;ascii&quot;) if &quot;%&quot; in path: path = urllib.parse.unquote(path) full_path = self.root_path + path full_raw_path = self.root_path.encode(&quot;ascii&quot;) + raw_path self.scope[&quot;path&quot;] = full_path self.scope[&quot;raw_path&quot;] = full_raw_path self.scope[&quot;query_string&quot;] = parsed_url.query or b&quot;&quot; # Handle 503 responses when &#x27;limit_concurrency&#x27; is exceeded. if self.limit_concurrency is not None and ( len(self.connections) &gt;= self.limit_concurrency or len(self.tasks) &gt;= self.limit_concurrency ): # 当前并发数过高， 不再转发给后面的应用程序， 直接返回错误, 这里是一个具有ASGI标准函数签名的函数, 里面实现的功能是发送错误信息到socket app = service_unavailable message = &quot;Exceeded concurrency limit.&quot; self.logger.warning(message) else: app = self.app # cycle 相当于一个 request 的处理流程,普通的HTTP请求只对应一个cycle就可以了，这里是兼容Pipeline HTTP请求 existing_cycle = self.cycle self.cycle = RequestResponseCycle( scope=self.scope, transport=self.transport, flow=self.flow, logger=self.logger, access_logger=self.access_logger, access_log=self.access_log, default_headers=self.server_state.default_headers, message_event=asyncio.Event(), expect_100_continue=self.expect_100_continue, keep_alive=http_version != &quot;1.0&quot;, on_response=self.on_response_complete, ) if existing_cycle is None or existing_cycle.response_complete: # Standard case - start processing the request. # 如果上个请求已经处理完了， 则开始处理这个请求(通过run_asgi来运行) task = self.loop.create_task(self.cycle.run_asgi(app)) task.add_done_callback(self.tasks.discard) self.tasks.add(task) else: # 如果上个请求没有处理完(比如 body 没有接收完整)， 就先暂停读取数据， 并把该cycle放到pipeline暂存 # Pipelined HTTP requests need to be queued up. self.flow.pause_reading() self.pipeline.appendleft((self.cycle, app)) def on_body(self, body: bytes) -&gt; None: # 一个请求可能会有多次 on_body 调用，包括这里再往后就没有直接解析数据了，一般会发送到真正处理的应用程序（ASGI应用） if (self.parser.should_upgrade() and self._should_upgrade()) or self.cycle.response_complete: return # 将 body 累计到 cycle 中 self.cycle.body += body if len(self.cycle.body) &gt; HIGH_WATER_LIMIT: # 由于ASGI应用程序会根据调用者需要才来获取body(比如starlette的 await request.body())， 如果应用程序没有需要则会暂缓获取body数据 self.flow.pause_reading() # 告诉ASGI应用程序， body已经获取结束（通常在cycle的more_body为False的时候, 才会检查message_event） self.cycle.message_event.set() def on_message_complete(self) -&gt; None: if (self.parser.should_upgrade() and self._should_upgrade()) or self.cycle.response_complete: return # 表示body已经读取结束了 self.cycle.more_body = False self.cycle.message_event.set() def on_response_complete(self) -&gt; None: # Callback for pipelined HTTP requests to be started. self.server_state.total_requests += 1 if self.transport.is_closing(): return # 设置一个keep_alive的机制， 服务端返回响应后会设置一个倒计时future, 该future只有在上面data_received收到请求的时候才会取消 # 如果该future没有取消， 则会调用timeout_keep_alive_handler函数来关闭transport通道 self._unset_keepalive_if_required() # Unpause data reads if needed. self.flow.resume_reading() # Unblock any pipelined events. If there are none, arm the # Keep-Alive timeout instead. if self.pipeline: # 如果是pipeline请求， 则开始处理刚才暂存的cycle cycle, app = self.pipeline.pop() task = self.loop.create_task(cycle.run_asgi(app)) task.add_done_callback(self.tasks.discard) self.tasks.add(task) else: self.timeout_keep_alive_task = self.loop.call_later( self.timeout_keep_alive, self.timeout_keep_alive_handler ) PS: 什么是 pipeline 请求 在ASGI的上下文中，一个请求可能不会立即完成，而是会通过多个事件来分阶段处理。例如，一个HTTP请求可能首先接收到请求头，然后是请求体的一部分，然后是更多的请求体，直到所有的请求体都被接收。这个过程可以被看作是一个”pipeline”，其中请求数据在被完全接收和处理之前，会通过不同的阶段流动。 可以看到里面有一个 cycle 对象，是负责 http 和 asgi 数据转换的对象，它有 send 和 receive 两个方法 1234567891011121314151617181920212223 async def send(self, message: ASGISendEvent) -&gt; None: # 通过传入的参数message获取到ASGI应用程序返回的数据， 并依据ASGI协议进行解析， # 并拼接成HTTP协议的字节流， 当ASGI应用程序发送结束标记时， send会把拼接的字节 # 流通过socket返回给客户端, 同时触发on_response_complete 方法。 ... async def receive(self) -&gt; ASGIReceiveEvent: # 它只负责接收获取到已经解析完成的HTTP数据（前面on_xxx时会把数据传给cycle）， # 然后发送到 ASGI 应用程序中 if self.waiting_for_100_continue and not self.transport.is_closing(): self.transport.write(b&quot;HTTP/1.1 100 Continue\\r \\r &quot;) self.waiting_for_100_continue = False if not self.disconnected and not self.response_complete: self.flow.resume_reading() await self.message_event.wait() self.message_event.clear() if self.disconnected or self.response_complete: return &#123;&quot;type&quot;: &quot;http.disconnect&quot;&#125; message: HTTPRequestEvent = &#123;&quot;type&quot;: &quot;http.request&quot;, &quot;body&quot;: self.body, &quot;more_body&quot;: self.more_body&#125; self.body = b&quot;&quot; return message websocket里面也有两种实现：websockets 和 wsproto websockets 是一个独立的 Python 库，用于构建 WebSocket 服务器和客户端。它提供了一个高级的 API，允许开发者轻松地实现 WebSocket 通信。websockets 库处理了 WebSocket 协议的大部分复杂性，包括握手、帧编码和解码、心跳以及关闭过程。 wsproto 是一个较低级别的 WebSocket 协议库，它提供了 WebSocket 协议的实现，但不包括高级的框架或服务器逻辑。wsproto 主要用于那些需要精细控制 WebSocket 协议细节的场合，或者在性能要求极高的环境中。 流程图 可以看到 http 解析器中只解析到 header，具体的 body 内容是交给 ASGI 应用去处理 supervisorsuvicorn本身是以一个进程启动的， 这个文件夹存放着uvicorn的几种启动方式， 如多进程启动，监控文件变动自动重启的方式等 启动work.py里面有个类 UvicornWorker 用于gunicorn启动 uvicorn 1gunicorn main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:80 logging.py里面定义了一些 formatter 比如根据日志等级渲染不同颜色等 整个项目用到了三个 logger： uvicorn.error 错误日志或生命周期日志 uvicorn.access http 请求访问日志 uvicorn.asgi ASGI 应用相关的日志 日志的定义使用了 dictConfig，之前倒是没用过这种方式配置日志, 感觉不是很方便 1234567891011121314151617181920212223242526class Config: def configure_logging(self) -&gt; None: logging.addLevelName(TRACE_LOG_LEVEL, &quot;TRACE&quot;) if self.log_config is not None: if isinstance(self.log_config, dict): if self.use_colors in (True, False): self.log_config[&quot;formatters&quot;][&quot;default&quot;][&quot;use_colors&quot;] = self.use_colors self.log_config[&quot;formatters&quot;][&quot;access&quot;][&quot;use_colors&quot;] = self.use_colors logging.config.dictConfig(self.log_config) elif self.log_config.endswith(&quot;.json&quot;): with open(self.log_config) as file: loaded_config = json.load(file) logging.config.dictConfig(loaded_config) elif self.log_config.endswith((&quot;.yaml&quot;, &quot;.yml&quot;)): # Install the PyYAML package or the uvicorn[standard] optional # dependencies to enable this functionality. import yaml with open(self.log_config) as file: loaded_config = yaml.safe_load(file) logging.config.dictConfig(loaded_config) else: # See the note about fileConfig() here: # https://docs.python.org/3/library/logging.config.html#configuration-file-format logging.config.fileConfig(self.log_config, disable_existing_loggers=False) main.py123456789101112131415161718192021222324252627def run(app, **kwargs) -&gt; None: if app_dir is not None: sys.path.insert(0, app_dir) # 初始化配置 config = Config(app, **kwargs) # 初始化服务 server = Server(config=config) if (config.reload or config.workers &gt; 1) and not isinstance(app, str): logger = logging.getLogger(&quot;uvicorn.error&quot;) logger.warning(&quot;You must pass the application as an import string to enable &#x27;reload&#x27; or &quot; &quot;&#x27;workers&#x27;.&quot;) sys.exit(1) if config.should_reload: sock = config.bind_socket() ChangeReload(config, target=server.run, sockets=[sock]).run() elif config.workers &gt; 1: sock = config.bind_socket() Multiprocess(config, target=server.run, sockets=[sock]).run() else: server.run() if config.uds and os.path.exists(config.uds): os.remove(config.uds) # pragma: py-win32 if not server.started and not config.should_reload and config.workers == 1: sys.exit(STARTUP_FAILURE) server.py12345678910111213141516171819202122232425262728293031323334class Server: def run(self, sockets: list[socket.socket] | None = None) -&gt; None: # 设置循环策略 self.config.setup_event_loop() # 启动服务 return asyncio.run(self.serve(sockets=sockets)) async def serve(self, sockets: list[socket.socket] | None = None) -&gt; None: with self.capture_signals(): await self._serve(sockets) async def _serve(self, sockets: list[socket.socket] | None = None) -&gt; None: process_id = os.getpid() config = self.config if not config.loaded: config.load() self.lifespan = config.lifespan_class(config) message = &quot;Started server process [%d]&quot; color_message = &quot;Started server process [&quot; + click.style(&quot;%d&quot;, fg=&quot;cyan&quot;) + &quot;]&quot; logger.info(message, process_id, extra=&#123;&quot;color_message&quot;: color_message&#125;) await self.startup(sockets=sockets) if self.should_exit: return await self.main_loop() await self.shutdown(sockets=sockets) message = &quot;Finished server process [%d]&quot; color_message = &quot;Finished server process [&quot; + click.style(&quot;%d&quot;, fg=&quot;cyan&quot;) + &quot;]&quot; logger.info(message, process_id, extra=&#123;&quot;color_message&quot;: color_message&#125;) 我们看看 startup() ，main_loop() 和 shutdown()里面有什么 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162async def startup(self, sockets: list[socket.socket] | None = None) -&gt; None: await self.lifespan.startup() if self.lifespan.should_exit: self.should_exit = True return config = self.config def create_protocol( _loop: asyncio.AbstractEventLoop | None = None, ) -&gt; asyncio.Protocol: return config.http_protocol_class( # type: ignore[call-arg] config=config, server_state=self.server_state, app_state=self.lifespan.state, _loop=_loop, ) loop = asyncio.get_running_loop() listeners: Sequence[socket.SocketType] if sockets is not None: # pragma: full coverage # 当用户传socket过来的时候： 基于该scoket和create_protocol创建服务， # 如果是多进程且是Windows系统， 则要显示的共享socket。 ... elif config.fd is not None: # pragma: py-win32 # 当用户传文件描述符的时候： 基于该文件描述符获取scoket， 并通过该socket # 和create_protocol创建服务。 ... elif config.uds is not None: # pragma: py-win32 # 当用户传unix domain socket的时候: 基于unix domain socket和 # create_protocol创建服务。 ... else: # 当用户传host和port参数的时候: 基于host和port和create_protocol创建服务。 try: server = await loop.create_server( create_protocol, host=config.host, port=config.port, ssl=config.ssl, backlog=config.backlog, ) except OSError as exc: logger.error(exc) await self.lifespan.shutdown() sys.exit(1) assert server.sockets is not None listeners = server.sockets self.servers = [server] if sockets is None: self._log_started_message(listeners) else: # We&#x27;re most likely running multiple workers, so a message has already been # logged by `config.bind_socket()`. pass # pragma: full coverage self.started = True 每次循环执行的时候都会调用on_tick方法， 该方法主要是进行服务统计以及判断啥时候可以退出服务, 比如请求总数超过配置的限制数， 或者收到信号，把变量should_exit设置为True等等 123456789async def main_loop(self) -&gt; None: counter = 0 should_exit = await self.on_tick(counter) # 是个死循环，防止主程序退出 while not should_exit: counter += 1 counter = counter % 864000 await asyncio.sleep(0.1) should_exit = await self.on_tick(counter) 如果在循环中判断程序需要进行退出, 就会进入退出逻辑shutdown 123456789101112131415161718192021222324252627282930313233async def shutdown(self, sockets=None): logger.info(&quot;Shutting down&quot;) # 关闭socket， 不让有新的连接建立 for server in self.servers: server.close() for sock in sockets or []: sock.close() for server in self.servers: await server.wait_closed() # 关闭已经创建的连接， 并等待他们处理完毕 for connection in list(self.server_state.connections): connection.shutdown() await asyncio.sleep(0.1) # 等待连接关闭或者用户强制关闭 if self.server_state.connections and not self.force_exit: msg = &quot;Waiting for connections to close. (CTRL+C to force quit)&quot; logger.info(msg) while self.server_state.connections and not self.force_exit: await asyncio.sleep(0.1) # 等待后台任务完成或者用户强制关闭 if self.server_state.tasks and not self.force_exit: msg = &quot;Waiting for background tasks to complete. (CTRL+C to force quit)&quot; logger.info(msg) while self.server_state.tasks and not self.force_exit: await asyncio.sleep(0.1) # 通过lifespan告诉ASGI应用程序即将关闭 if not self.force_exit: await self.lifespan.shutdown() 启动流程图","tags":["python","uvicron"]},{"title":"Python ORM 集成","path":"/2023/06/25/Python ORM 集成/","content":"python 常用的 ORM 框架非 flask_sqlalchemy 莫属，当然也可以自己直接根据 sqlalchemy 进行封装 flask_sqlalchemy&#x3D;&#x3D;3.0.5 pymysql&#x3D;&#x3D;1.1.0 目录结构 1234567891011121314151617flask_demo:\t-- api: -- file -- file.py -- user -- user.py -- __init__.py\t-- utils -- log.py -- database.py -- restful.py\t-- model -- user.py\t-- service -- user.py\t-- manage.py\t-- requirements.txt 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960utils/database.pyfrom contextlib import contextmanagerfrom flask_sqlalchemy import SQLAlchemyclass MySQLAlchemy(SQLAlchemy): @contextmanager def auto_commit(self): try: yield self.session.commit() except Exception as e: self.session.rollback() raise edb = MySQLAlchemy()model/user.pyfrom model.base import HasTime, AutoincrementId, BaseTablefrom sqlalchemy import Column, String, SMALLINTclass User(BaseTable, HasTime, AutoincrementId): __tablename__ = &quot;user&quot; name = Column(String(10)) email = Column(String(50), nullable=False, unique=True) role = Column(String(10), nullable=False, default=&quot;user&quot;) delete_status = Column(SMALLINT, nullable=False, default=0) service/user.pyfrom model.user import Userclass UserService(object): @staticmethod def query_by_id(user_id: int) -&gt; dict: user = User.query.filter_by(id=user_id).first() return user.to_dict()api/user/user.pyimport loggingfrom flask import Blueprintfrom service.user import UserServicefrom uitls.restful import JsonResfrom uitls.log import log_requestbp = Blueprint(&#x27;user&#x27;, __name__, url_prefix=&quot;/user&quot;)LOG = logging.getLogger(__name__)@bp.route(&#x27;/get&#x27;, methods=[&#x27;GET&#x27;])@log_request()def get_user(): user = UserService.query_by_id(1) return JsonRes(200, True, user)api/__init__.py create_app 方法中添加以下内容 1234567891011sql_config = &#123; &quot;SQLALCHEMY_DATABASE_URI&quot;: &quot;mysql+pymysql://root:root@localhost:3306/flask_demo?charset=utf8&quot;, &quot;SQLALCHEMY_TRACK_MODIFICATIONS&quot;: False, &quot;SQLALCHEMY_ECHO&quot;: False, &quot;SQLALCHEMY_POOL_SIZE&quot;: 10, &quot;SQLALCHEMY_POOL_TIMEOUT&quot;: 60, &quot;SQLALCHEMY_POOL_RECYCLE&quot;: 600 &#125; app.config.update(sql_config) db.init_app(app)","tags":["python"]},{"title":"Python flask 框架","path":"/2023/05/22/Python flask 框架/","content":"写一个通用的小型 flask 框架 目录结构 12345678910flask_demo:\t-- api: -- file -- file.py -- __init__.py\t-- utils -- log.py -- restful.py\t-- manage.py\t-- requirements.txt 基准代码api/__init__.py1234567891011121314151617from flask import Flask, Blueprintfrom flask_cors import CORSfrom api.file.file import bp as file_bpdef create_app(): setup_log(log_level=&quot;debug&quot;, log_handler=&quot;file&quot;, log_dir=&quot;./logs&quot;, log_file_name=&quot;app.log&quot;) app = Flask(__name__) CORS(app) app_bp = Blueprint(&#x27;api&#x27;, __name__, url_prefix=&#x27;/api&#x27;) app_bp.register_blueprint(file_bp) app.register_blueprint(app_bp) return app utils/log.py1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import loggingimport logging.handlersimport os.pathfrom functools import wrapsfrom flask import requestDEBUG_LOG_FORMAT = &#x27;%(threadName)s %(thread)s %(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s &#x27; \\ &#x27;%(funcName)s %(lineno)d [-] %(message)s&#x27;INFO_LOG_FORMAT = &#x27;%(threadName)s %(thread)s %(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s &#x27; \\ &#x27;%(lineno)d [-] %(message)s&#x27;def setup_log(log_level, log_handler, log_dir, log_file_name, backupCount=1): logger = logging.getLogger() if log_level == &quot;DEBUG&quot;: logger.setLevel(logging.DEBUG) formatter = logging.Formatter(DEBUG_LOG_FORMAT) else: logger.setLevel(logging.INFO) formatter = logging.Formatter(INFO_LOG_FORMAT) if log_handler == &quot;file&quot;: if not os.path.exists(log_dir): os.makedirs(log_dir) loghandler = logging.handlers.RotatingFileHandler( filename=os.path.join(log_dir, log_file_name), maxBytes=1000000000, backupCount=backupCount) loghandler.setFormatter(formatter) else: loghandler = logging.StreamHandler() loghandler.setFormatter(formatter) logger.addHandler(loghandler) return loggerdef log_request(f): @wraps(f) def wrapsed(*args, **kwargs): log = logging.getLogger(__name__) log.info(&#x27;API request url %s&#x27;, request.url) if request.query_string: log.info(&#x27;API query string %s&#x27;, request.query_string) log.info(&#x27;API request method %s&#x27;, request.method) if request.method == &quot;POST&quot;: log.info(&quot;API POST data %s&quot;, request.json) if request.method == &quot;PUT&quot;: log.info(&quot;API PUT data %s&quot;, request.json) log.debug(&#x27;API request environ %s&#x27;, request.environ) return f(*args, **kwargs) return wrapsed utils/restful.py1234567891011121314151617181920212223242526272829303132333435import datetimeimport jsonfrom flask import Response_SIMPLE_TYPE = (str, int, type(None), bool, float)def json_encoder(value): if isinstance(value, _SIMPLE_TYPE): return value if isinstance(value, datetime.datetime): return value.isoformat() + &quot;Z&quot; elif isinstance(value, Exception): return &#123; &quot;exception&quot;: value.__class__.__name__, &quot;message&quot;: str(value) &#125;class JsonRes(Response): def __init__(self, code=200, status=True, data=None, error=None): self.res = &#123; &#x27;code&#x27;: code, &#x27;status&#x27;: status, &#125; if data is not None: self.res[&#x27;data&#x27;] = data if error is not None: self.res[&#x27;error&#x27;] = error content = json.dumps(self.res, default=json_encoder) try: super().__init__(content, status=code, mimetype=&quot;application/json&quot;) except TypeError: super(JsonRes, self).__init__(content, status=code, mimetype=&quot;application/json&quot;) manage.py123456from api import create_appapp = create_app()if __name__ == &#x27;__main__&#x27;: app.run(debug=True) file.py123456789101112131415import osfrom flask import Blueprint, requestfrom uitls.api_response import APIResponsefrom uitls.log import log_requestbp = Blueprint(&#x27;file&#x27;, __name__, url_prefix=&quot;/file&quot;)logger = logging.get_logger(__name__)@bp.route(&#x27;/&#x27;, methods=[&#x27;GET&#x27;])@log_requestdef hello(): logger.info(&quot;hello world&quot;) return JsonRes(200, True, &#123;&#x27;hi&#x27;: &#x27;hi&#x27;&#125;)","tags":["python"]},{"title":"Python celery 集成","path":"/2023/05/22/Python celery 集成/","content":"celery&#x3D;&#x3D;5.2.7, redis&#x3D;&#x3D;4.5.5 目录结构 123456789101112flask_demo:\t-- api: -- celery -- celery.py -- file -- file.py -- __init__.py\t-- utils -- log.py -- restful.py\t-- manage.py\t-- requirements.txt 在 api/__init__.py 中添加以下方法 1234567891011121314151617181920212223242526def celery_init_app(app): celery_app = Celery(app.name) celery_app.config_from_object(app.config[&quot;CELERY&quot;]) celery_app.set_default() app.extensions[&quot;celery&quot;] = celery_app return celery_appdef creat_app():\t...some code\tapp = Flask(__name__) app.config.from_mapping( CELERY=dict( broker_url=&quot;redis://localhost:6379/0&quot;, result_backend=&quot;redis://localhost:6379/1&quot;, task_ignore_result=True, task_serializer=&#x27;json&#x27;, accept_content=[&#x27;json&#x27;], result_serializer=&#x27;json&#x27; ), ) app.config.from_prefixed_env() celery_init_app(app) ... another code 在 app.py 12app = create_app()celery = app.extensions[&quot;celery&quot;] 在 utils/tasks.py 中添加任务 不要在 task 方法中调用其他类的方法，task 方法是异步任务，调用其他方法会报错 1234567891011from __future__ import absolute_import, unicode_literalsimport timefrom celery import shared_task@shared_task(ignore_result=False)def test1(x, y): time.sleep(1) return x + y 注意：直接按照 flask 官方文档配置会有错误出现 celery 启动方式 123456789101112131415# windows 只能用 threads 启动，否则任务无法执行celery -A app.celery worker -c 4 -l info -P threads参数说明：\tapp:celery # app 指的是 app.py celery 是 app.py 中的 celery 对象\t-P # 启动方式: prefork：默认的并发方式，即多进程的方式。 eventlet：使用eventlet方式启动worker。 gevent：使用gevent方式启动worker。 solo：单进程的方式。 threads：使用线程的方式\t-l # log 级别\t-c # worker 数量\t当 -P 指定为 gevent 或 eventlet 时，需要安装对应的依赖 celery task 的结果默认存储时间是 1 天，可以通过 result_expires 配置","tags":["python"]},{"title":"Python日志json格式","path":"/2023/05/22/Python日志json格式/","content":"python 在工作中的 log 日志一般是以特殊符号分开的方式，这样的形式方便 debug 查阅，但是并不利于数据处理与分析。json 格式就很不错，可以更好地组织、分析和利用日志数据，从而为应用程序的调试、故障排查和性能优化提供更多的洞察力 示例要求：将 flask 的每个请求都记录下来 log.py 需要安装 pip install python-json-logger 不安装 python-json-logger 也可以实现，只要将 JSON_LOG_FORMATTER 写成 json 字符串的格式，或者使用json.dumps() 你要输出的字段即可，但是这种方式改写的 json 格式 key 和 value 固定为 string 类型 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import loggingimport osimport timefrom functools import wrapsfrom flask import requestfrom pythonjsonlogger import jsonloggerJSON_LOG_FORMATTER = &quot;%(appName)s %(service)s %(asctime)s %(levelname)s %(message)s %(request)s %(response)s %(rt)s&quot;class JSONFilter(logging.Filter): rt = 0 appName = &quot;myapp&quot; response = &#123;&#125; def request_parse(self): params = &#123;&#125; if request.method == &quot;GET&quot;: params = request.args.to_dict() elif request.method == &quot;POST&quot; or request.method == &quot;PUT&quot;: if request.form: params = request.form.to_dict() else: params = request.get_json() return params def filter(self, record): record.message = record.msg record.service = f&quot;&#123;request.method&#125; &#123;request.path&#125;&quot; record.appName = self.appName record.rt = self.rt record.request = self.request_parse() record.response = self.response return Truedef make_dirs(path): if not os.path.exists(path): os.makedirs(path) return pathdef set_monitor_logger(log_path, name): logger = logging.getLogger(name) logger.setLevel(logging.DEBUG) formatter = jsonlogger.JsonFormatter(JSON_LOG_FORMATTER) json_filter = JSONFilter() logger.addFilter(json_filter) handler = logging.StreamHandler() handler.setFormatter(formatter) file_handler = logging.FileHandler(os.path.join(make_dirs(log_path), f&quot;&#123;name&#125;.log&quot;)) file_handler.setFormatter(formatter) logger.addHandler(handler) logger.addHandler(file_handler) return loggermonitor_logger = set_monitor_logger(&quot;monitor&quot;)def log_request(func): @wraps(func) def wrapped(*args, **kwargs): _filter = monitor_logger.filters[0] start_time = time.time() response = func(*args, **kwargs) _filter.rt = round(time.time() - start_time, 3) _filter.response = response.json monitor_logger.info(&quot;&quot;) return response return wrapped xxxxxxxxxx sql_config &#x3D; { “SQLALCHEMY_DATABASE_URI”: “mysql+pymysql:&#x2F;&#x2F;root:root@localhost:3306&#x2F;flask_demo?charset&#x3D;utf8”, “SQLALCHEMY_TRACK_MODIFICATIONS”: False, “SQLALCHEMY_ECHO”: False, “SQLALCHEMY_POOL_SIZE”: 10, “SQLALCHEMY_POOL_TIMEOUT”: 60, “SQLALCHEMY_POOL_RECYCLE”: 600 } app.config.update(sql_config) db.init_app(app)python","tags":["python"]},{"title":"Python 文件上传","path":"/2023/05/19/Python-文件上传/","content":"针对大文件分片上传然后合并可以使用前端解决方案 webuploader 组件 后端接口1234567891011121314151617181920212223242526272829303132333435363738394041import osfrom flask import Blueprint, requestfrom uitls.api_response import JsonResfrom uitls.log import log_requestbp = Blueprint(&#x27;file&#x27;, __name__, url_prefix=&quot;/file&quot;)@bp.route(&#x27;/upload/accept&#x27;, methods=[&#x27;POST&#x27;])@log_request()def upload(): upload_file = request.files[&#x27;file&#x27;] task = request.form.get(&#x27;task_id&#x27;) chunk = request.form.get(&#x27;chunk&#x27;, 0) filename = &#x27;%s%s&#x27; % (task, chunk) upload_file.save(&#x27;./upload/%s&#x27; % filename) return JsonRes(200, True, &#123;&#x27;filename&#x27;: filename&#125;)@bp.route(&quot;/upload/complete&quot;, methods=[&#x27;GET&#x27;])@log_request()def upload_complete(): target_filename = request.args.get(&#x27;filename&#x27;) task = request.args.get(&#x27;task_id&#x27;) chunk = 0 with open(&#x27;./upload/%s&#x27; % target_filename, &#x27;wb&#x27;) as target_file: while True: try: filename = &#x27;./upload/%s%d&#x27; % (task, chunk) source_file = open(filename, &#x27;rb&#x27;) target_file.write(source_file.read()) source_file.close() except IOError: break chunk += 1 os.remove(filename) return JsonRes(200, True) 前端页面12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970index.html&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt; &lt;script src=&quot;../static/jquery-1.11.1.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;../static/bootstrap/js/bootstrap.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;../static/webuploader/webuploader.min.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../static/webuploader/webuploader.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../static/bootstrap/css/bootstrap.min.css&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; &lt;div id=&quot;picker&quot;&gt;请选择&lt;/div&gt; &lt;!-- 上传按钮，必须指定id选择器的值 --&gt; &lt;div class=&quot;progress&quot;&gt; &lt;!-- 进度条 --&gt; &lt;div class=&quot;progress-bar progress-bar-striped active&quot; role=&quot;progressbar&quot; style=&quot;width:0%;&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;script type=&quot;text/javascript&quot;&gt; $(document).ready(function() &#123; var task_id = WebUploader.Base.guid(); //产生task_id var uploader = WebUploader.create(&#123; //创建上传控件 swf: &#x27;../static/webuploader/Uploader.swf&#x27;, //swf位置，这个可能与flash有关 server: &#x27;http://localhost:5000/api/file/upload/accept&#x27;, //接收每一个分片的服务器地址 pick: &#x27;#picker&#x27;, //填上传按钮的id选择器值 auto: true, //选择文件后，是否自动上传 chunked: true, //是否分片 chunkSize: 20 * 1024 * 1024, //每个分片的大小，这里为20M chunkRetry: 3, //某分片若上传失败，重试次数 threads: 1, //线程数量，考虑到服务器，这里就选了1 duplicate: true, //分片是否自动去重 formData: &#123; //每次上传分片，一起携带的数据 task_id: task_id, &#125;, &#125;); uploader.on(&#x27;startUpload&#x27;, function() &#123; //开始上传时，调用该方法 $(&#x27;.progress-bar&#x27;).css(&#x27;width&#x27;, &#x27;0%&#x27;); $(&#x27;.progress-bar&#x27;).text(&#x27;0%&#x27;); &#125;); uploader.on(&#x27;uploadProgress&#x27;, function(file, percentage) &#123; //一个分片上传成功后，调用该方法 $(&#x27;.progress-bar&#x27;).css(&#x27;width&#x27;, percentage * 100 - 1 + &#x27;%&#x27;); $(&#x27;.progress-bar&#x27;).text(Math.floor(percentage * 100 - 1) + &#x27;%&#x27;); &#125;); uploader.on(&#x27;uploadSuccess&#x27;, function(file) &#123; //整个文件的所有分片都上传成功，调用该方法 //上传的信息（文件唯一标识符，文件名） var data = &#123;&#x27;task_id&#x27;: task_id, &#x27;filename&#x27;: file.source[&#x27;name&#x27;] &#125;; $.get(&#x27;http://localhost:5000/api/file/upload/complete&#x27;, data); //ajax携带data向该url发请求 $(&#x27;.progress-bar&#x27;).css(&#x27;width&#x27;, &#x27;100%&#x27;); $(&#x27;.progress-bar&#x27;).text(&#x27;上传完成&#x27;); &#125;); uploader.on(&#x27;uploadError&#x27;, function(file) &#123; //上传过程中发生异常，调用该方法 $(&#x27;.progress-bar&#x27;).css(&#x27;width&#x27;, &#x27;100%&#x27;); $(&#x27;.progress-bar&#x27;).text(&#x27;上传失败&#x27;); &#125;); uploader.on(&#x27;uploadComplete&#x27;, function(file) &#123;//上传结束，无论文件最终是否上传成功，该方法都会被调用 $(&#x27;.progress-bar&#x27;).removeClass(&#x27;active progress-bar-striped&#x27;); &#125;); &#125;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 前端页面依赖的 js css 等可以在 https://github.com/xinmos/xinmos.github.io/tree/master/asset/upload/ 下载","tags":["python"]},{"title":"Python 装饰器","path":"/2023/05/19/Python-装饰器/","content":"在 python flask 一文中 utils/log.py 中定义了一个装饰器，用于将所有的网络请求记入到日志中 那如何定义一个带参数的装饰器呢？ 最简单的装饰器123456789101112131415161718192021222324252627282930313233343536373839from functools import wrapsdef decorator(func): def wrapper(*args, **kwargs): # 添加额外的功能或修改行为 print(&quot;在调用函数之前做一些事情&quot;) result = func(*args, **kwargs) print(&quot;在调用函数之后做一些事情&quot;) return result return wrapperdef decorator2(func): @wraps(func) def wrapper(*args, **kwargs): # 添加额外的功能或修改行为 print(&quot;在调用函数之前做一些事情&quot;) result = func(*args, **kwargs) print(&quot;在调用函数之后做一些事情&quot;) return result return wrapper@decoratordef test1(): print(&quot;run test1&quot;)@decorator2def test2(): print(&quot;run test2&quot;)if __name__ == &#x27;__main__&#x27;: test1() print(&quot;test1 func name: &quot;, test1.__name__) test2() print(&quot;test2 func name: &quot;, test2.__name__) 输出: 12345678在调用函数之前做一些事情run test1在调用函数之后做一些事情test1 func name: wrapper在调用函数之前做一些事情run test2在调用函数之后做一些事情test2 func name: test2 @wraps 作用@wraps是Python中的一个装饰器，它可以用来将被装饰函数的元信息（如函数名、参数列表等）复制到装饰器函数中，从而使得装饰器函数也具有被装饰函数的元信息。这样做的好处是，可以让被装饰函数在使用时更加方便，因为它们的元信息不会被修改 带参数的装饰器在装饰器的外面再包裹一层 1234567891011121314151617181920212223from functools import wrapsdef log_request(on=True): def decorator(func): @wraps(func) def wrapper(*args, **kwargs): print(&quot;args: on=&quot;, on) print(&quot;在调用函数之前做一些事情&quot;) result = func(*args, **kwargs) print(&quot;在调用函数之后做一些事情&quot;) return result return wrapper return decorator@log_request(on=False)def test(): print(&quot;run test&quot;)if __name__ == &#x27;__main__&#x27;: test() 输出： 1234args: on= False在调用函数之前做一些事情run test在调用函数之后做一些事情 可以使用 @log_request() 但是无法直接使用 @log_request，即使 on 已经设置了默认值。 兼容型装饰器12345678910111213141516171819202122232425262728293031323334353637383940from functools import wrapsdef log_request(origin_func=None, on=True): def decorator(func): @wraps(func) def wrapper(*args, **kwargs): print(&quot;args: on=&quot;, on) print(&quot;在调用函数之前做一些事情&quot;) result = func(*args, **kwargs) print(&quot;在调用函数之后做一些事情&quot;) return result return wrapper if origin_func is None: return decorator else: return decorator(origin_func)@log_requestdef test(): print(&quot;run test&quot;)@log_request()def test2(): print(&quot;run test2&quot;)@log_request(on=False)def test3(): print(&quot;run test3&quot;)if __name__ == &#x27;__main__&#x27;: test() print(&quot;-------------&quot;) test2() print(&quot;-------------&quot;) test3() 输出： 1234567891011121314args: on= True在调用函数之前做一些事情run test在调用函数之后做一些事情-------------args: on= True在调用函数之前做一些事情run test2在调用函数之后做一些事情-------------args: on= False在调用函数之前做一些事情run test3在调用函数之后做一些事情","tags":["python"]},{"title":"Python Asyncio","path":"/2023/05/19/Python-Asyncio/","content":"协程 一个抽象概念，在计算机中不存在 协程（Coroutione），也可以被称为微线程，是一种用户态内的上下文切换技术。 实现方法 yield 关键字 asyncio 装饰器（在 py 3.4 之后建议用 第三种方法） async、await 关键字 yield 关键字12345678910111213# 通过 yield 切换上下文def func1(): yield 1 yield from func2() yield 2def func2(): yield 3 yield 4f1 = func1()for item in f1: print(item) asyncio123456789101112131415161718import asyncioasync def func1(): print(1) await asyncio.sleep(2) # 遇到 IO 耗时操作，自动切换到 tasks 中的其他任务 print(2)async def func2(): print(3) await asyncio.sleep(2) print(4)loop = asyncio.get_event_loop()tasks = [asyncio.ensure_future(func1()), asyncio.ensure_future(func2())]loop.run_until_complete(asyncio.wait(tasks))# py 3.7 以后asyncio.run(tasks) 异步编程事件循环理解为一个死循环，去检测并执行某些代码 1234567891011121314# 伪代码task_list = [task1, task2,...]while True: 可执行的任务列表，已完成的任务列表 for 就绪任务 in 可执行任务列表 执行 for 已完成任务 in 已完成任务列表 移除 if 可执行任务为 0： break 协程函数 用 async def func() 定义的函数 12345async def func(): passresult = func()# 协程函数只创建协程对象，函数内部代码不会执行 await await + 可等待对象 （协程对象、Future、IO等待） 等待后面的对象执行完成后在执行下一步任务（单线程内和顺序执行差不多） 123456789101112131415import asyncioasync def func1(): print(1) await asyncio.sleep(2) # 遇到 IO 耗时操作，自动切换到 tasks 中的其他任务 print(2)async def func2(): print(3) await func1() print(4)asyncio.run(func2())# 输出 3，1，2，4 Task 对象 在事件循环中添加多个任务 Tasks 用于并发调度协程，通过 asyncio.create_task() 的方式创建 Task 对象，这样可以让协程加入时间循环中等待被调度执行。除了使用 asyncio.create_task() 函数以外，还可同底层级别的 loop.create_task() 或 asyncio.ensure_future() 函数。不建议手动实例化 Task 对象 注意：asyncio.create_task() 在 python3.7 之后才被加入，该版本之前用 asyncio.ensure_future() 12345678910111213141516171819202122232425import asyncioasync def func(): print(1) await asyncio.sleep(2) print(2) return &quot;the Return&quot;async def main(): print(&quot;main start&quot;) # 创建 task 对象，将 func 添加到事件循环 task1 = asyncio.create_task(func()) task2 = asyncio.create_task(func()) print(&quot;main end&quot;) # 当某协程遇到 阻塞（I/O、sleep）会自动切换到其他任务 ret1 = await task1 ret2 = await task2 print(ret1, ret2)asyncio.run(main()) 用的少，下面的比较常用 123456789101112131415161718192021222324import asyncioasync def func(): print(1) await asyncio.sleep(2) print(2) return &quot;the Return&quot;async def main(): print(&quot;main start&quot;) task_list = [ asyncio.create_task(func()), asyncio.create_task(func()) ] print(&quot;main end&quot;) # done 为执行完之后的结果，pending 为未执行完的结果 done, pending = await asyncio.wait(task_list) print(done, pending)asyncio.run(main()) 第三种 12345678910111213141516import asyncioasync def func(): print(1) await asyncio.sleep(2) print(2) return &quot;the Return&quot;task_list = [ func(), func()]done, pending = asyncio.run(asyncio.wait(task_list))print(done, pending) asyncio.FutureTask 继承 Future 对象，Task 对象内部 await 结果的处理基于 Future 对象来的。 12345678async def main(): # 获取当前事件循环 loop = asyncio.get_running_loop() # # 创建一个任务（Future对象），这个任务什么都不干。 fut = loop.create_future() # 等待任务最终结果（Future对象），没有结果则会一直等下去。 await futasyncio.run(main()) 示例2： 123456789101112131415161718import asyncioasync def set_after(fut): await asyncio.sleep(2) fut.set_result(&quot;666&quot;) async def main(): # 获取当前事件循环 loop = asyncio.get_running_loop() # 创建一个任务（Future对象），没绑定任何行为，则这个任务永远不知道什么时候结束。 fut = loop.create_future() # 创建一个任务（Task对象），绑定了set_after函数，函数内部在2s之后，会给fut赋值。 # 即手动设置future任务的最终结果，那么fut就可以结束了。 await loop.create_task(set_after(fut)) # 等待 Future对象获取 最终结果，否则一直等下去 data = await fut print(data) asyncio.run(main()) Future对象本身函数进行绑定，所以想要让事件循环获取Future的结果，则需要手动设置。而Task对象继承了Future对象，其实就对Future进行扩展，他可以实现在对应绑定的函数执行完成之后，自动执行set_result，从而实现自动结束。 虽然，平时使用的是Task对象，但对于结果的处理本质是基于Future对象来实现的。 concurrent.futures.Future 和 asyncio.Future 没有任何关系 使用线程池、进程池实现异步操作时用到的对象 123456789101112131415import timefrom concurrent.futures import Futurefrom concurrent.futures.thread import ThreadPoolExecutorfrom concurrent.futures.process import ProcessPoolExecutodef func(value): time.sleep(1) print(value) pool = ThreadPoolExecutor(max_workers=5)# 或 pool = ProcessPoolExecutor(max_workers=5)for i in range(10): fut = pool.submit(func, i) print(fut) 两个Future对象是不同的，他们是为不同的应用场景而设计，例如：concurrent.futures.Future不支持await语法 等。 官方提示两对象之间不同： unlike asyncio Futures, concurrent.futures.Future instances cannot be awaited. asyncio.Future.result() and asyncio.Future.exception() do not accept the timeout argument. asyncio.Future.result() and asyncio.Future.exception() raise an InvalidStateError exception when the Future is not done. Callbacks registered with asyncio.Future.add_done_callback() are not called immediately. They are scheduled with loop.call_soon() instead. asyncio Future is not compatible with the concurrent.futures.wait() and concurrent.futures.as_completed() functions. 在Python提供了一个将futures.Future 对象包装成asyncio.Future对象的函数 asynic.wrap_future。 接下里你肯定问：为什么python会提供这种功能？ 其实，一般在程序开发中我们要么统一使用 asycio 的协程实现异步操作、要么都使用进程池和线程池实现异步操作。但如果 协程的异步和 进程池/线程池的异步 混搭时，那么就会用到此功能了。 12345678910111213141516171819202122232425262728import timeimport asyncioimport concurrent.futuresdef func1(): # 某个耗时操作 time.sleep(2) return &quot;SB&quot;async def main(): loop = asyncio.get_running_loop() # 1. Run in the default loop&#x27;s executor ( 默认ThreadPoolExecutor ) # 第一步：内部会先调用 ThreadPoolExecutor 的 submit 方法去线程池中申请一个线程去执行func1函数，并返回一个concurrent.futures.Future对象 # 第二步：调用asyncio.wrap_future将concurrent.futures.Future对象包装为asycio.Future对象。 # 因为concurrent.futures.Future对象不支持await语法，所以需要包装为 asycio.Future对象 才能使用。 fut = loop.run_in_executor(None, func1) result = await fut print(&#x27;default thread pool&#x27;, result) # 2. Run in a custom thread pool: # with concurrent.futures.ThreadPoolExecutor() as pool: # result = await loop.run_in_executor( # pool, func1) # print(&#x27;custom thread pool&#x27;, result) # 3. Run in a custom process pool: # with concurrent.futures.ProcessPoolExecutor() as pool: # result = await loop.run_in_executor( # pool, func1) # print(&#x27;custom process pool&#x27;, result)asyncio.run(main()) 应用场景：当项目以协程式的异步编程开发时，如果要使用一个第三方模块，而第三方模块不支持协程方式异步编程时，就需要用到这个功能，例如： 12345678910111213141516171819202122232425import asyncioimport requestsasync def download_image(url): # 发送网络请求，下载图片（遇到网络下载图片的IO请求，自动化切换到其他任务） print(&quot;开始下载:&quot;, url) loop = asyncio.get_event_loop() # requests模块默认不支持异步操作，所以就使用线程池来配合实现了。 future = loop.run_in_executor(None, requests.get, url) response = await future print(&#x27;下载完成&#x27;) # 图片保存到本地文件 file_name = url.rsplit(&#x27;_&#x27;)[-1] with open(file_name, mode=&#x27;wb&#x27;) as file_object: file_object.write(response.content) if __name__ == &#x27;__main__&#x27;: url_list = [ &#x27;https://www3.autoimg.cn/newsdfs/g26/M02/35/A9/120x90_0_autohomecar__ChsEe12AXQ6AOOH_AAFocMs8nzU621.jpg&#x27;, &#x27;https://www2.autoimg.cn/newsdfs/g30/M01/3C/E2/120x90_0_autohomecar__ChcCSV2BBICAUntfAADjJFd6800429.jpg&#x27;, &#x27;https://www3.autoimg.cn/newsdfs/g26/M0B/3C/65/120x90_0_autohomecar__ChcCP12BFCmAIO83AAGq7vK0sGY193.jpg&#x27; ] tasks = [download_image(url) for url in url_list] loop = asyncio.get_event_loop() loop.run_until_complete( asyncio.wait(tasks) ) 异步迭代器uvloopPython标准库中提供了asyncio模块，用于支持基于协程的异步编程。 uvloop是 asyncio 中的事件循环的替代方案，替换后可以使得asyncio性能提高。事实上，uvloop要比nodejs、gevent等其他python异步框架至少要快2倍，性能可以比肩Go语言。 安装uvloop 1pip3 install uvloop 在项目中想要使用uvloop替换asyncio的事件循环也非常简单，只要在代码中这么做就行。 12345678import asyncioimport uvloopasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())# 编写asyncio的代码，与之前写的代码一致。# 内部的事件循环自动化会变为uvloopasyncio.run(...) 注意：知名的asgi uvicorn内部就是使用的uvloop的事件循环。 实战案例异步 Redis当通过 Python 去操作 redis 时，连接、设置值、获取值 这些都涉及网络 IO 请求，使用 asyncio 异步的方式可以在 IO 等待时去做一些其他任务，从而提升性能 安装Python异步操作redis模块 1pip3 install aioredis 示例1：异步操作redis。 1234567891011121314151617181920#!/usr/bin/env python# -*- coding:utf-8 -*-import asyncioimport aioredisasync def execute(address, password): print(&quot;开始执行&quot;, address) # 网络IO操作：创建redis连接 redis = await aioredis.create_redis(address, password=password) # 网络IO操作：在redis中设置哈希值car，内部在设三个键值对，即： redis = &#123; car:&#123;key1:1,key2:2,key3:3&#125;&#125; await redis.hmset_dict(&#x27;car&#x27;, key1=1, key2=2, key3=3) # 网络IO操作：去redis中获取值 result = await redis.hgetall(&#x27;car&#x27;, encoding=&#x27;utf-8&#x27;) print(result) redis.close() # 网络IO操作：关闭redis连接 await redis.wait_closed() print(&quot;结束&quot;, address) asyncio.run(execute(&#x27;redis://47.93.4.198:6379&#x27;, &quot;root!2345&quot;)) 示例2：连接多个redis做操作（遇到IO会切换其他任务，提供了性能）。 1234567891011121314151617181920212223import asyncioimport aioredisasync def execute(address, password): print(&quot;开始执行&quot;, address) # 网络IO操作：先去连接 47.93.4.197:6379，遇到IO则自动切换任务，去连接47.93.4.198:6379 redis = await aioredis.create_redis_pool(address, password=password) # 网络IO操作：遇到IO会自动切换任务 await redis.hmset_dict(&#x27;car&#x27;, key1=1, key2=2, key3=3) # 网络IO操作：遇到IO会自动切换任务 result = await redis.hgetall(&#x27;car&#x27;, encoding=&#x27;utf-8&#x27;) print(result) redis.close() # 网络IO操作：遇到IO会自动切换任务 await redis.wait_closed() print(&quot;结束&quot;, address) task_list = [ execute(&#x27;redis://47.93.4.197:6379&#x27;, &quot;root!2345&quot;), execute(&#x27;redis://47.93.4.198:6379&#x27;, &quot;root!2345&quot;)]asyncio.run(asyncio.wait(task_list)) 官网：https://aioredis.readthedocs.io/en/v1.3.0/start.html 爬虫123456789101112131415161718192021import aiohttpimport asyncioasync def fetch(session, url): print(&quot;发送请求：&quot;, url) async with session.get(url, verify_ssl=False) as response: text = await response.text() print(&quot;得到结果：&quot;, url, len(text)) async def main(): async with aiohttp.ClientSession() as session: url_list = [ &#x27;https://python.org&#x27;, &#x27;https://www.baidu.com&#x27;, &#x27;https://www.pythonav.com&#x27; ] tasks = [asyncio.create_task(fetch(session, url)) for url in url_list] await asyncio.wait(tasks) if __name__ == &#x27;__main__&#x27;: asyncio.run(main()) 对比requests requests.post 每次都会创建新的连接，速度较慢。如果首先初始化一个 session，那么 requests 会保持连接，大大提高请求速度 12session = requests.Session()# session 只对同一个链接请求多次的场景下有效 不借助其他第三方库的情况下 requests：只能发送同步请求 aiohttp: 只能发送异步请求 httpx: 既能发送同步请求，又能发送异步请求 总结 如果你只发几条请求。那么使用 requests 或者 httpx 的同步模式，代码最简单。 requests 是否创建一个 session 保持连接，速度差别比较大，在没有反爬的情况下，只追求速度，建议用 requests.session () 如果你要发送很多请求，但是有些地方要发送同步请求，有些地方要发送异步请求，那么使用 httpx 最省事。 如果你要发送很多请求，并且越快越好，那么使用 aiohttp 最快。 问题路径1234os.path.join(cur_path, &quot;\\asdff.csv&quot;)字符串 &quot;\\asdff.csv&quot; 会导致从系统根目录开始加载当 flask 运行时，os.getcwd() 获取的时项目根目录","tags":["python"]}]