[{"path":"/2024/10/07/Python celery 集成/","content":"12title: Python celery 集成date: 2023/5/22 20:46:25 celery&#x3D;&#x3D;5.2.7, redis&#x3D;&#x3D;4.5.5 目录结构 123456789101112flask_demo:\t-- api: -- celery -- celery.py -- file -- file.py -- __init__.py\t-- utils -- log.py -- restful.py\t-- manage.py\t-- requirements.txt 在 api/__init__.py 中添加以下方法 1234567891011121314151617181920212223242526def celery_init_app(app): celery_app = Celery(app.name) celery_app.config_from_object(app.config[&quot;CELERY&quot;]) celery_app.set_default() app.extensions[&quot;celery&quot;] = celery_app return celery_appdef creat_app():\t...some code\tapp = Flask(__name__) app.config.from_mapping( CELERY=dict( broker_url=&quot;redis://localhost:6379/0&quot;, result_backend=&quot;redis://localhost:6379/1&quot;, task_ignore_result=True, task_serializer=&#x27;json&#x27;, accept_content=[&#x27;json&#x27;], result_serializer=&#x27;json&#x27; ), ) app.config.from_prefixed_env() celery_init_app(app) ... another code 在 app.py 12app = create_app()celery = app.extensions[&quot;celery&quot;] 在 utils/tasks.py 中添加任务 不要在 task 方法中调用其他类的方法，task 方法是异步任务，调用其他方法会报错 1234567891011from __future__ import absolute_import, unicode_literalsimport timefrom celery import shared_task@shared_task(ignore_result=False)def test1(x, y): time.sleep(1) return x + y 注意：直接按照 flask 官方文档配置会有错误出现 celery 启动方式 123456789101112131415# windows 只能用 threads 启动，否则任务无法执行celery -A app.celery worker -c 4 -l info -P threads参数说明：\tapp:celery # app 指的是 app.py celery 是 app.py 中的 celery 对象\t-P # 启动方式: prefork：默认的并发方式，即多进程的方式。 eventlet：使用eventlet方式启动worker。 gevent：使用gevent方式启动worker。 solo：单进程的方式。 threads：使用线程的方式\t-l # log 级别\t-c # worker 数量\t当 -P 指定为 gevent 或 eventlet 时，需要安装对应的依赖 celery task 的结果默认存储时间是 1 天，可以通过 result_expires 配置"},{"title":"Python flask 框架","path":"/2023/05/22/Python flask 框架/","content":"写一个通用的小型 flask 框架 目录结构 12345678910flask_demo:\t-- api: -- file -- file.py -- __init__.py\t-- utils -- log.py -- restful.py\t-- manage.py\t-- requirements.txt 基准代码api/__init__.py1234567891011121314151617from flask import Flask, Blueprintfrom flask_cors import CORSfrom api.file.file import bp as file_bpdef create_app(): setup_log(log_level=&quot;debug&quot;, log_handler=&quot;file&quot;, log_dir=&quot;./logs&quot;, log_file_name=&quot;app.log&quot;) app = Flask(__name__) CORS(app) app_bp = Blueprint(&#x27;api&#x27;, __name__, url_prefix=&#x27;/api&#x27;) app_bp.register_blueprint(file_bp) app.register_blueprint(app_bp) return app utils/log.py1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import loggingimport logging.handlersimport os.pathfrom functools import wrapsfrom flask import requestDEBUG_LOG_FORMAT = &#x27;%(threadName)s %(thread)s %(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s &#x27; \\ &#x27;%(funcName)s %(lineno)d [-] %(message)s&#x27;INFO_LOG_FORMAT = &#x27;%(threadName)s %(thread)s %(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s &#x27; \\ &#x27;%(lineno)d [-] %(message)s&#x27;def setup_log(log_level, log_handler, log_dir, log_file_name, backupCount=1): logger = logging.getLogger() if log_level == &quot;DEBUG&quot;: logger.setLevel(logging.DEBUG) formatter = logging.Formatter(DEBUG_LOG_FORMAT) else: logger.setLevel(logging.INFO) formatter = logging.Formatter(INFO_LOG_FORMAT) if log_handler == &quot;file&quot;: if not os.path.exists(log_dir): os.makedirs(log_dir) loghandler = logging.handlers.RotatingFileHandler( filename=os.path.join(log_dir, log_file_name), maxBytes=1000000000, backupCount=backupCount) loghandler.setFormatter(formatter) else: loghandler = logging.StreamHandler() loghandler.setFormatter(formatter) logger.addHandler(loghandler) return loggerdef log_request(f): @wraps(f) def wrapsed(*args, **kwargs): log = logging.getLogger(__name__) log.info(&#x27;API request url %s&#x27;, request.url) if request.query_string: log.info(&#x27;API query string %s&#x27;, request.query_string) log.info(&#x27;API request method %s&#x27;, request.method) if request.method == &quot;POST&quot;: log.info(&quot;API POST data %s&quot;, request.json) if request.method == &quot;PUT&quot;: log.info(&quot;API PUT data %s&quot;, request.json) log.debug(&#x27;API request environ %s&#x27;, request.environ) return f(*args, **kwargs) return wrapsed utils/restful.py1234567891011121314151617181920212223242526272829303132333435import datetimeimport jsonfrom flask import Response_SIMPLE_TYPE = (str, int, type(None), bool, float)def json_encoder(value): if isinstance(value, _SIMPLE_TYPE): return value if isinstance(value, datetime.datetime): return value.isoformat() + &quot;Z&quot; elif isinstance(value, Exception): return &#123; &quot;exception&quot;: value.__class__.__name__, &quot;message&quot;: str(value) &#125;class JsonRes(Response): def __init__(self, code=200, status=True, data=None, error=None): self.res = &#123; &#x27;code&#x27;: code, &#x27;status&#x27;: status, &#125; if data is not None: self.res[&#x27;data&#x27;] = data if error is not None: self.res[&#x27;error&#x27;] = error content = json.dumps(self.res, default=json_encoder) try: super().__init__(content, status=code, mimetype=&quot;application/json&quot;) except TypeError: super(JsonRes, self).__init__(content, status=code, mimetype=&quot;application/json&quot;) manage.py123456from api import create_appapp = create_app()if __name__ == &#x27;__main__&#x27;: app.run(debug=True) file.py123456789101112131415import osfrom flask import Blueprint, requestfrom uitls.api_response import APIResponsefrom uitls.log import log_requestbp = Blueprint(&#x27;file&#x27;, __name__, url_prefix=&quot;/file&quot;)logger = logging.get_logger(__name__)@bp.route(&#x27;/&#x27;, methods=[&#x27;GET&#x27;])@log_requestdef hello(): logger.info(&quot;hello world&quot;) return JsonRes(200, True, &#123;&#x27;hi&#x27;: &#x27;hi&#x27;&#125;)"},{"title":"Python日志json格式","path":"/2023/05/22/Python日志json格式/","content":"python 在工作中的 log 日志一般是以特殊符号分开的方式，这样的形式方便 debug 查阅，但是并不利于数据处理与分析。json 格式就很不错，可以更好地组织、分析和利用日志数据，从而为应用程序的调试、故障排查和性能优化提供更多的洞察力 示例要求：将 flask 的每个请求都记录下来 log.py 需要安装 pip install python-json-logger 不安装 python-json-logger 也可以实现，只要将 JSON_LOG_FORMATTER 写成 json 字符串的格式，或者使用json.dumps() 你要输出的字段即可，但是这种方式改写的 json 格式 key 和 value 固定为 string 类型 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import loggingimport osimport timefrom functools import wrapsfrom flask import requestfrom pythonjsonlogger import jsonloggerJSON_LOG_FORMATTER = &quot;%(appName)s %(service)s %(asctime)s %(levelname)s %(message)s %(request)s %(response)s %(rt)s&quot;class JSONFilter(logging.Filter): rt = 0 appName = &quot;myapp&quot; response = &#123;&#125; def request_parse(self): params = &#123;&#125; if request.method == &quot;GET&quot;: params = request.args.to_dict() elif request.method == &quot;POST&quot; or request.method == &quot;PUT&quot;: if request.form: params = request.form.to_dict() else: params = request.get_json() return params def filter(self, record): record.message = record.msg record.service = f&quot;&#123;request.method&#125; &#123;request.path&#125;&quot; record.appName = self.appName record.rt = self.rt record.request = self.request_parse() record.response = self.response return Truedef make_dirs(path): if not os.path.exists(path): os.makedirs(path) return pathdef set_monitor_logger(log_path, name): logger = logging.getLogger(name) logger.setLevel(logging.DEBUG) formatter = jsonlogger.JsonFormatter(JSON_LOG_FORMATTER) json_filter = JSONFilter() logger.addFilter(json_filter) handler = logging.StreamHandler() handler.setFormatter(formatter) file_handler = logging.FileHandler(os.path.join(make_dirs(log_path), f&quot;&#123;name&#125;.log&quot;)) file_handler.setFormatter(formatter) logger.addHandler(handler) logger.addHandler(file_handler) return loggermonitor_logger = set_monitor_logger(&quot;monitor&quot;)def log_request(func): @wraps(func) def wrapped(*args, **kwargs): _filter = monitor_logger.filters[0] start_time = time.time() response = func(*args, **kwargs) _filter.rt = round(time.time() - start_time, 3) _filter.response = response.json monitor_logger.info(&quot;&quot;) return response return wrapped xxxxxxxxxx sql_config &#x3D; { “SQLALCHEMY_DATABASE_URI”: “mysql+pymysql:&#x2F;&#x2F;root:root@localhost:3306&#x2F;flask_demo?charset&#x3D;utf8”, “SQLALCHEMY_TRACK_MODIFICATIONS”: False, “SQLALCHEMY_ECHO”: False, “SQLALCHEMY_POOL_SIZE”: 10, “SQLALCHEMY_POOL_TIMEOUT”: 60, “SQLALCHEMY_POOL_RECYCLE”: 600 } app.config.update(sql_config) db.init_app(app)python"},{"title":"Python Asyncio","path":"/2023/05/19/Python-Asyncio/","content":"协程 一个抽象概念，在计算机中不存在 协程（Coroutione），也可以被称为微线程，是一种用户态内的上下文切换技术。 实现方法 yield 关键字 asyncio 装饰器（在 py 3.4 之后建议用 第三种方法） async、await 关键字 yield 关键字12345678910111213# 通过 yield 切换上下文def func1(): yield 1 yield from func2() yield 2def func2(): yield 3 yield 4f1 = func1()for item in f1: print(item) asyncio123456789101112131415161718import asyncioasync def func1(): print(1) await asyncio.sleep(2) # 遇到 IO 耗时操作，自动切换到 tasks 中的其他任务 print(2)async def func2(): print(3) await asyncio.sleep(2) print(4)loop = asyncio.get_event_loop()tasks = [asyncio.ensure_future(func1()), asyncio.ensure_future(func2())]loop.run_until_complete(asyncio.wait(tasks))# py 3.7 以后asyncio.run(tasks) 异步编程事件循环理解为一个死循环，去检测并执行某些代码 1234567891011121314# 伪代码task_list = [task1, task2,...]while True: 可执行的任务列表，已完成的任务列表 for 就绪任务 in 可执行任务列表 执行 for 已完成任务 in 已完成任务列表 移除 if 可执行任务为 0： break 协程函数 用 async def func() 定义的函数 12345async def func(): passresult = func()# 协程函数只创建协程对象，函数内部代码不会执行 await await + 可等待对象 （协程对象、Future、IO等待） 等待后面的对象执行完成后在执行下一步任务（单线程内和顺序执行差不多） 123456789101112131415import asyncioasync def func1(): print(1) await asyncio.sleep(2) # 遇到 IO 耗时操作，自动切换到 tasks 中的其他任务 print(2)async def func2(): print(3) await func1() print(4)asyncio.run(func2())# 输出 3，1，2，4 Task 对象 在事件循环中添加多个任务 Tasks 用于并发调度协程，通过 asyncio.create_task() 的方式创建 Task 对象，这样可以让协程加入时间循环中等待被调度执行。除了使用 asyncio.create_task() 函数以外，还可同底层级别的 loop.create_task() 或 asyncio.ensure_future() 函数。不建议手动实例化 Task 对象 注意：asyncio.create_task() 在 python3.7 之后才被加入，该版本之前用 asyncio.ensure_future() 12345678910111213141516171819202122232425import asyncioasync def func(): print(1) await asyncio.sleep(2) print(2) return &quot;the Return&quot;async def main(): print(&quot;main start&quot;) # 创建 task 对象，将 func 添加到事件循环 task1 = asyncio.create_task(func()) task2 = asyncio.create_task(func()) print(&quot;main end&quot;) # 当某协程遇到 阻塞（I/O、sleep）会自动切换到其他任务 ret1 = await task1 ret2 = await task2 print(ret1, ret2)asyncio.run(main()) 用的少，下面的比较常用 123456789101112131415161718192021222324import asyncioasync def func(): print(1) await asyncio.sleep(2) print(2) return &quot;the Return&quot;async def main(): print(&quot;main start&quot;) task_list = [ asyncio.create_task(func()), asyncio.create_task(func()) ] print(&quot;main end&quot;) # done 为执行完之后的结果，pending 为未执行完的结果 done, pending = await asyncio.wait(task_list) print(done, pending)asyncio.run(main()) 第三种 12345678910111213141516import asyncioasync def func(): print(1) await asyncio.sleep(2) print(2) return &quot;the Return&quot;task_list = [ func(), func()]done, pending = asyncio.run(asyncio.wait(task_list))print(done, pending) asyncio.FutureTask 继承 Future 对象，Task 对象内部 await 结果的处理基于 Future 对象来的。 12345678async def main(): # 获取当前事件循环 loop = asyncio.get_running_loop() # # 创建一个任务（Future对象），这个任务什么都不干。 fut = loop.create_future() # 等待任务最终结果（Future对象），没有结果则会一直等下去。 await futasyncio.run(main()) 示例2： 123456789101112131415161718import asyncioasync def set_after(fut): await asyncio.sleep(2) fut.set_result(&quot;666&quot;) async def main(): # 获取当前事件循环 loop = asyncio.get_running_loop() # 创建一个任务（Future对象），没绑定任何行为，则这个任务永远不知道什么时候结束。 fut = loop.create_future() # 创建一个任务（Task对象），绑定了set_after函数，函数内部在2s之后，会给fut赋值。 # 即手动设置future任务的最终结果，那么fut就可以结束了。 await loop.create_task(set_after(fut)) # 等待 Future对象获取 最终结果，否则一直等下去 data = await fut print(data) asyncio.run(main()) Future对象本身函数进行绑定，所以想要让事件循环获取Future的结果，则需要手动设置。而Task对象继承了Future对象，其实就对Future进行扩展，他可以实现在对应绑定的函数执行完成之后，自动执行set_result，从而实现自动结束。 虽然，平时使用的是Task对象，但对于结果的处理本质是基于Future对象来实现的。 concurrent.futures.Future 和 asyncio.Future 没有任何关系 使用线程池、进程池实现异步操作时用到的对象 123456789101112131415import timefrom concurrent.futures import Futurefrom concurrent.futures.thread import ThreadPoolExecutorfrom concurrent.futures.process import ProcessPoolExecutodef func(value): time.sleep(1) print(value) pool = ThreadPoolExecutor(max_workers=5)# 或 pool = ProcessPoolExecutor(max_workers=5)for i in range(10): fut = pool.submit(func, i) print(fut) 两个Future对象是不同的，他们是为不同的应用场景而设计，例如：concurrent.futures.Future不支持await语法 等。 官方提示两对象之间不同： unlike asyncio Futures, concurrent.futures.Future instances cannot be awaited. asyncio.Future.result() and asyncio.Future.exception() do not accept the timeout argument. asyncio.Future.result() and asyncio.Future.exception() raise an InvalidStateError exception when the Future is not done. Callbacks registered with asyncio.Future.add_done_callback() are not called immediately. They are scheduled with loop.call_soon() instead. asyncio Future is not compatible with the concurrent.futures.wait() and concurrent.futures.as_completed() functions. 在Python提供了一个将futures.Future 对象包装成asyncio.Future对象的函数 asynic.wrap_future。 接下里你肯定问：为什么python会提供这种功能？ 其实，一般在程序开发中我们要么统一使用 asycio 的协程实现异步操作、要么都使用进程池和线程池实现异步操作。但如果 协程的异步和 进程池/线程池的异步 混搭时，那么就会用到此功能了。 12345678910111213141516171819202122232425262728import timeimport asyncioimport concurrent.futuresdef func1(): # 某个耗时操作 time.sleep(2) return &quot;SB&quot;async def main(): loop = asyncio.get_running_loop() # 1. Run in the default loop&#x27;s executor ( 默认ThreadPoolExecutor ) # 第一步：内部会先调用 ThreadPoolExecutor 的 submit 方法去线程池中申请一个线程去执行func1函数，并返回一个concurrent.futures.Future对象 # 第二步：调用asyncio.wrap_future将concurrent.futures.Future对象包装为asycio.Future对象。 # 因为concurrent.futures.Future对象不支持await语法，所以需要包装为 asycio.Future对象 才能使用。 fut = loop.run_in_executor(None, func1) result = await fut print(&#x27;default thread pool&#x27;, result) # 2. Run in a custom thread pool: # with concurrent.futures.ThreadPoolExecutor() as pool: # result = await loop.run_in_executor( # pool, func1) # print(&#x27;custom thread pool&#x27;, result) # 3. Run in a custom process pool: # with concurrent.futures.ProcessPoolExecutor() as pool: # result = await loop.run_in_executor( # pool, func1) # print(&#x27;custom process pool&#x27;, result)asyncio.run(main()) 应用场景：当项目以协程式的异步编程开发时，如果要使用一个第三方模块，而第三方模块不支持协程方式异步编程时，就需要用到这个功能，例如： 12345678910111213141516171819202122232425import asyncioimport requestsasync def download_image(url): # 发送网络请求，下载图片（遇到网络下载图片的IO请求，自动化切换到其他任务） print(&quot;开始下载:&quot;, url) loop = asyncio.get_event_loop() # requests模块默认不支持异步操作，所以就使用线程池来配合实现了。 future = loop.run_in_executor(None, requests.get, url) response = await future print(&#x27;下载完成&#x27;) # 图片保存到本地文件 file_name = url.rsplit(&#x27;_&#x27;)[-1] with open(file_name, mode=&#x27;wb&#x27;) as file_object: file_object.write(response.content) if __name__ == &#x27;__main__&#x27;: url_list = [ &#x27;https://www3.autoimg.cn/newsdfs/g26/M02/35/A9/120x90_0_autohomecar__ChsEe12AXQ6AOOH_AAFocMs8nzU621.jpg&#x27;, &#x27;https://www2.autoimg.cn/newsdfs/g30/M01/3C/E2/120x90_0_autohomecar__ChcCSV2BBICAUntfAADjJFd6800429.jpg&#x27;, &#x27;https://www3.autoimg.cn/newsdfs/g26/M0B/3C/65/120x90_0_autohomecar__ChcCP12BFCmAIO83AAGq7vK0sGY193.jpg&#x27; ] tasks = [download_image(url) for url in url_list] loop = asyncio.get_event_loop() loop.run_until_complete( asyncio.wait(tasks) ) 异步迭代器uvloopPython标准库中提供了asyncio模块，用于支持基于协程的异步编程。 uvloop是 asyncio 中的事件循环的替代方案，替换后可以使得asyncio性能提高。事实上，uvloop要比nodejs、gevent等其他python异步框架至少要快2倍，性能可以比肩Go语言。 安装uvloop 1pip3 install uvloop 在项目中想要使用uvloop替换asyncio的事件循环也非常简单，只要在代码中这么做就行。 12345678import asyncioimport uvloopasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())# 编写asyncio的代码，与之前写的代码一致。# 内部的事件循环自动化会变为uvloopasyncio.run(...) 注意：知名的asgi uvicorn内部就是使用的uvloop的事件循环。 实战案例异步 Redis当通过 Python 去操作 redis 时，连接、设置值、获取值 这些都涉及网络 IO 请求，使用 asyncio 异步的方式可以在 IO 等待时去做一些其他任务，从而提升性能 安装Python异步操作redis模块 1pip3 install aioredis 示例1：异步操作redis。 1234567891011121314151617181920#!/usr/bin/env python# -*- coding:utf-8 -*-import asyncioimport aioredisasync def execute(address, password): print(&quot;开始执行&quot;, address) # 网络IO操作：创建redis连接 redis = await aioredis.create_redis(address, password=password) # 网络IO操作：在redis中设置哈希值car，内部在设三个键值对，即： redis = &#123; car:&#123;key1:1,key2:2,key3:3&#125;&#125; await redis.hmset_dict(&#x27;car&#x27;, key1=1, key2=2, key3=3) # 网络IO操作：去redis中获取值 result = await redis.hgetall(&#x27;car&#x27;, encoding=&#x27;utf-8&#x27;) print(result) redis.close() # 网络IO操作：关闭redis连接 await redis.wait_closed() print(&quot;结束&quot;, address) asyncio.run(execute(&#x27;redis://47.93.4.198:6379&#x27;, &quot;root!2345&quot;)) 示例2：连接多个redis做操作（遇到IO会切换其他任务，提供了性能）。 1234567891011121314151617181920212223import asyncioimport aioredisasync def execute(address, password): print(&quot;开始执行&quot;, address) # 网络IO操作：先去连接 47.93.4.197:6379，遇到IO则自动切换任务，去连接47.93.4.198:6379 redis = await aioredis.create_redis_pool(address, password=password) # 网络IO操作：遇到IO会自动切换任务 await redis.hmset_dict(&#x27;car&#x27;, key1=1, key2=2, key3=3) # 网络IO操作：遇到IO会自动切换任务 result = await redis.hgetall(&#x27;car&#x27;, encoding=&#x27;utf-8&#x27;) print(result) redis.close() # 网络IO操作：遇到IO会自动切换任务 await redis.wait_closed() print(&quot;结束&quot;, address) task_list = [ execute(&#x27;redis://47.93.4.197:6379&#x27;, &quot;root!2345&quot;), execute(&#x27;redis://47.93.4.198:6379&#x27;, &quot;root!2345&quot;)]asyncio.run(asyncio.wait(task_list)) 官网：https://aioredis.readthedocs.io/en/v1.3.0/start.html 爬虫123456789101112131415161718192021import aiohttpimport asyncioasync def fetch(session, url): print(&quot;发送请求：&quot;, url) async with session.get(url, verify_ssl=False) as response: text = await response.text() print(&quot;得到结果：&quot;, url, len(text)) async def main(): async with aiohttp.ClientSession() as session: url_list = [ &#x27;https://python.org&#x27;, &#x27;https://www.baidu.com&#x27;, &#x27;https://www.pythonav.com&#x27; ] tasks = [asyncio.create_task(fetch(session, url)) for url in url_list] await asyncio.wait(tasks) if __name__ == &#x27;__main__&#x27;: asyncio.run(main()) 对比requests requests.post 每次都会创建新的连接，速度较慢。如果首先初始化一个 session，那么 requests 会保持连接，大大提高请求速度 12session = requests.Session()# session 只对同一个链接请求多次的场景下有效 不借助其他第三方库的情况下 requests：只能发送同步请求 aiohttp: 只能发送异步请求 httpx: 既能发送同步请求，又能发送异步请求 总结 如果你只发几条请求。那么使用 requests 或者 httpx 的同步模式，代码最简单。 requests 是否创建一个 session 保持连接，速度差别比较大，在没有反爬的情况下，只追求速度，建议用 requests.session () 如果你要发送很多请求，但是有些地方要发送同步请求，有些地方要发送异步请求，那么使用 httpx 最省事。 如果你要发送很多请求，并且越快越好，那么使用 aiohttp 最快。 问题路径1234os.path.join(cur_path, &quot;\\asdff.csv&quot;)字符串 &quot;\\asdff.csv&quot; 会导致从系统根目录开始加载当 flask 运行时，os.getcwd() 获取的时项目根目录"},{"title":"Python 装饰器","path":"/2023/05/19/Python-装饰器/","content":"在 python flask 一文中 utils/log.py 中定义了一个装饰器，用于将所有的网络请求记入到日志中 那如何定义一个带参数的装饰器呢？ 最简单的装饰器123456789101112131415161718192021222324252627282930313233343536373839from functools import wrapsdef decorator(func): def wrapper(*args, **kwargs): # 添加额外的功能或修改行为 print(&quot;在调用函数之前做一些事情&quot;) result = func(*args, **kwargs) print(&quot;在调用函数之后做一些事情&quot;) return result return wrapperdef decorator2(func): @wraps(func) def wrapper(*args, **kwargs): # 添加额外的功能或修改行为 print(&quot;在调用函数之前做一些事情&quot;) result = func(*args, **kwargs) print(&quot;在调用函数之后做一些事情&quot;) return result return wrapper@decoratordef test1(): print(&quot;run test1&quot;)@decorator2def test2(): print(&quot;run test2&quot;)if __name__ == &#x27;__main__&#x27;: test1() print(&quot;test1 func name: &quot;, test1.__name__) test2() print(&quot;test2 func name: &quot;, test2.__name__) 输出: 12345678在调用函数之前做一些事情run test1在调用函数之后做一些事情test1 func name: wrapper在调用函数之前做一些事情run test2在调用函数之后做一些事情test2 func name: test2 @wraps 作用@wraps是Python中的一个装饰器，它可以用来将被装饰函数的元信息（如函数名、参数列表等）复制到装饰器函数中，从而使得装饰器函数也具有被装饰函数的元信息。这样做的好处是，可以让被装饰函数在使用时更加方便，因为它们的元信息不会被修改 带参数的装饰器在装饰器的外面再包裹一层 1234567891011121314151617181920212223from functools import wrapsdef log_request(on=True): def decorator(func): @wraps(func) def wrapper(*args, **kwargs): print(&quot;args: on=&quot;, on) print(&quot;在调用函数之前做一些事情&quot;) result = func(*args, **kwargs) print(&quot;在调用函数之后做一些事情&quot;) return result return wrapper return decorator@log_request(on=False)def test(): print(&quot;run test&quot;)if __name__ == &#x27;__main__&#x27;: test() 输出： 1234args: on= False在调用函数之前做一些事情run test在调用函数之后做一些事情 可以使用 @log_request() 但是无法直接使用 @log_request，即使 on 已经设置了默认值。 兼容型装饰器12345678910111213141516171819202122232425262728293031323334353637383940from functools import wrapsdef log_request(origin_func=None, on=True): def decorator(func): @wraps(func) def wrapper(*args, **kwargs): print(&quot;args: on=&quot;, on) print(&quot;在调用函数之前做一些事情&quot;) result = func(*args, **kwargs) print(&quot;在调用函数之后做一些事情&quot;) return result return wrapper if origin_func is None: return decorator else: return decorator(origin_func)@log_requestdef test(): print(&quot;run test&quot;)@log_request()def test2(): print(&quot;run test2&quot;)@log_request(on=False)def test3(): print(&quot;run test3&quot;)if __name__ == &#x27;__main__&#x27;: test() print(&quot;-------------&quot;) test2() print(&quot;-------------&quot;) test3() 输出： 1234567891011121314args: on= True在调用函数之前做一些事情run test在调用函数之后做一些事情-------------args: on= True在调用函数之前做一些事情run test2在调用函数之后做一些事情-------------args: on= False在调用函数之前做一些事情run test3在调用函数之后做一些事情"},{"title":"Python 文件上传","path":"/2023/05/19/Python-文件上传/","content":"针对大文件分片上传然后合并可以使用前端解决方案 webuploader 组件 后端接口1234567891011121314151617181920212223242526272829303132333435363738394041import osfrom flask import Blueprint, requestfrom uitls.api_response import JsonResfrom uitls.log import log_requestbp = Blueprint(&#x27;file&#x27;, __name__, url_prefix=&quot;/file&quot;)@bp.route(&#x27;/upload/accept&#x27;, methods=[&#x27;POST&#x27;])@log_request()def upload(): upload_file = request.files[&#x27;file&#x27;] task = request.form.get(&#x27;task_id&#x27;) chunk = request.form.get(&#x27;chunk&#x27;, 0) filename = &#x27;%s%s&#x27; % (task, chunk) upload_file.save(&#x27;./upload/%s&#x27; % filename) return JsonRes(200, True, &#123;&#x27;filename&#x27;: filename&#125;)@bp.route(&quot;/upload/complete&quot;, methods=[&#x27;GET&#x27;])@log_request()def upload_complete(): target_filename = request.args.get(&#x27;filename&#x27;) task = request.args.get(&#x27;task_id&#x27;) chunk = 0 with open(&#x27;./upload/%s&#x27; % target_filename, &#x27;wb&#x27;) as target_file: while True: try: filename = &#x27;./upload/%s%d&#x27; % (task, chunk) source_file = open(filename, &#x27;rb&#x27;) target_file.write(source_file.read()) source_file.close() except IOError: break chunk += 1 os.remove(filename) return JsonRes(200, True) 前端页面12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970index.html&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt; &lt;script src=&quot;../static/jquery-1.11.1.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;../static/bootstrap/js/bootstrap.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;../static/webuploader/webuploader.min.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../static/webuploader/webuploader.css&quot;&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../static/bootstrap/css/bootstrap.min.css&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; &lt;div id=&quot;picker&quot;&gt;请选择&lt;/div&gt; &lt;!-- 上传按钮，必须指定id选择器的值 --&gt; &lt;div class=&quot;progress&quot;&gt; &lt;!-- 进度条 --&gt; &lt;div class=&quot;progress-bar progress-bar-striped active&quot; role=&quot;progressbar&quot; style=&quot;width:0%;&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;script type=&quot;text/javascript&quot;&gt; $(document).ready(function() &#123; var task_id = WebUploader.Base.guid(); //产生task_id var uploader = WebUploader.create(&#123; //创建上传控件 swf: &#x27;../static/webuploader/Uploader.swf&#x27;, //swf位置，这个可能与flash有关 server: &#x27;http://localhost:5000/api/file/upload/accept&#x27;, //接收每一个分片的服务器地址 pick: &#x27;#picker&#x27;, //填上传按钮的id选择器值 auto: true, //选择文件后，是否自动上传 chunked: true, //是否分片 chunkSize: 20 * 1024 * 1024, //每个分片的大小，这里为20M chunkRetry: 3, //某分片若上传失败，重试次数 threads: 1, //线程数量，考虑到服务器，这里就选了1 duplicate: true, //分片是否自动去重 formData: &#123; //每次上传分片，一起携带的数据 task_id: task_id, &#125;, &#125;); uploader.on(&#x27;startUpload&#x27;, function() &#123; //开始上传时，调用该方法 $(&#x27;.progress-bar&#x27;).css(&#x27;width&#x27;, &#x27;0%&#x27;); $(&#x27;.progress-bar&#x27;).text(&#x27;0%&#x27;); &#125;); uploader.on(&#x27;uploadProgress&#x27;, function(file, percentage) &#123; //一个分片上传成功后，调用该方法 $(&#x27;.progress-bar&#x27;).css(&#x27;width&#x27;, percentage * 100 - 1 + &#x27;%&#x27;); $(&#x27;.progress-bar&#x27;).text(Math.floor(percentage * 100 - 1) + &#x27;%&#x27;); &#125;); uploader.on(&#x27;uploadSuccess&#x27;, function(file) &#123; //整个文件的所有分片都上传成功，调用该方法 //上传的信息（文件唯一标识符，文件名） var data = &#123;&#x27;task_id&#x27;: task_id, &#x27;filename&#x27;: file.source[&#x27;name&#x27;] &#125;; $.get(&#x27;http://localhost:5000/api/file/upload/complete&#x27;, data); //ajax携带data向该url发请求 $(&#x27;.progress-bar&#x27;).css(&#x27;width&#x27;, &#x27;100%&#x27;); $(&#x27;.progress-bar&#x27;).text(&#x27;上传完成&#x27;); &#125;); uploader.on(&#x27;uploadError&#x27;, function(file) &#123; //上传过程中发生异常，调用该方法 $(&#x27;.progress-bar&#x27;).css(&#x27;width&#x27;, &#x27;100%&#x27;); $(&#x27;.progress-bar&#x27;).text(&#x27;上传失败&#x27;); &#125;); uploader.on(&#x27;uploadComplete&#x27;, function(file) &#123;//上传结束，无论文件最终是否上传成功，该方法都会被调用 $(&#x27;.progress-bar&#x27;).removeClass(&#x27;active progress-bar-striped&#x27;); &#125;); &#125;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 前端页面依赖的 js css 等可以在 https://github.com/xinmos/xinmos.github.io/tree/main/storage 下载"},{"title":"Python ORM 集成","path":"/2013/06/25/Python ORM 集成/","content":"python 常用的 ORM 框架非 flask_sqlalchemy 莫属，当然也可以自己直接根据 sqlalchemy 进行封装 flask_sqlalchemy&#x3D;&#x3D;3.0.5 pymysql&#x3D;&#x3D;1.1.0 目录结构 1234567891011121314151617flask_demo:\t-- api: -- file -- file.py -- user -- user.py -- __init__.py\t-- utils -- log.py -- database.py -- restful.py\t-- model -- user.py\t-- service -- user.py\t-- manage.py\t-- requirements.txt 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960utils/database.pyfrom contextlib import contextmanagerfrom flask_sqlalchemy import SQLAlchemyclass MySQLAlchemy(SQLAlchemy): @contextmanager def auto_commit(self): try: yield self.session.commit() except Exception as e: self.session.rollback() raise edb = MySQLAlchemy()model/user.pyfrom model.base import HasTime, AutoincrementId, BaseTablefrom sqlalchemy import Column, String, SMALLINTclass User(BaseTable, HasTime, AutoincrementId): __tablename__ = &quot;user&quot; name = Column(String(10)) email = Column(String(50), nullable=False, unique=True) role = Column(String(10), nullable=False, default=&quot;user&quot;) delete_status = Column(SMALLINT, nullable=False, default=0) service/user.pyfrom model.user import Userclass UserService(object): @staticmethod def query_by_id(user_id: int) -&gt; dict: user = User.query.filter_by(id=user_id).first() return user.to_dict()api/user/user.pyimport loggingfrom flask import Blueprintfrom service.user import UserServicefrom uitls.restful import JsonResfrom uitls.log import log_requestbp = Blueprint(&#x27;user&#x27;, __name__, url_prefix=&quot;/user&quot;)LOG = logging.getLogger(__name__)@bp.route(&#x27;/get&#x27;, methods=[&#x27;GET&#x27;])@log_request()def get_user(): user = UserService.query_by_id(1) return JsonRes(200, True, user)api/__init__.py create_app 方法中添加以下内容 1234567891011sql_config = &#123; &quot;SQLALCHEMY_DATABASE_URI&quot;: &quot;mysql+pymysql://root:root@localhost:3306/flask_demo?charset=utf8&quot;, &quot;SQLALCHEMY_TRACK_MODIFICATIONS&quot;: False, &quot;SQLALCHEMY_ECHO&quot;: False, &quot;SQLALCHEMY_POOL_SIZE&quot;: 10, &quot;SQLALCHEMY_POOL_TIMEOUT&quot;: 60, &quot;SQLALCHEMY_POOL_RECYCLE&quot;: 600 &#125; app.config.update(sql_config) db.init_app(app)"}]